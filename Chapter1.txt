{Г~л~а~в~а~1. Краткие сведения о методах статистики\\* и обработки данных} 

	\section{Данные, погрешности и их обработка} 


На практике данные не бывают точными. Реально нам известно приближенное
значение измеряемой величины, а также некоторая информация (качественная 
и количественная) о погрешности этого значения.  \index{неопределенность} 
На результаты измерений могут оказывать влияние изменчивость самих измеряемых величин, 
их непостоянство во времени или пространстве. На измерения могут влиять внешние неконтролируемые факторы, так 
называемые <<шумы>>. 
У применяемой аппаратуры имеются собственные погрешности. 
В процессе математической обработки данных на результат влияют
неизбежные неточности расчетов (ошибки представления,  округления и т.\,п.). 

В \cite{Malikov} погрешности измерений и наблюдений разделяются на три класса: 
\begin{list}{}{\leftmargin=14mm\itemsep=5pt\topsep=3pt\parsep=0pt} 
	\item [1.] 
	Систематические погрешности. \index{систематическая погрешность}
	\item[2.] 
	Случайные погрешности. \index{случайная погрешность}
	\item[3.] 
	Промахи или выбросы. \index{промах}\index{выброс} 
\end{list} 

\emph{Систематической погрешностью} измерения называется составляющая погрешности 
измерения, которая остается постоянной или изменяется по какому-то определенному 
закону при повторных измерениях одной и той же величины. \emph{Случайными погрешностями} 
называются неопределенные по своей величине и природе погрешности, в появлении каждой 
из которых не наблюдается какой-либо явной закономерности. 
\emph{Промахами} ( \emph{выбросами}), называются погрешности, приводящие к явному 
искажению результата измерений. 
Для выявления выбросов и промахов организуют специальный этап общей технологии 
обработки данных --- \emph{предобработку}, который предшествует применению формальных 
математических методов. На этом этапе промахи (выбросы)   должны быть определены и удалены 
из обрабатываемых данных.               \index{предобработка} 


Что касается случайных погрешностей, то в \cite{Malikov} указывается: <<%Слову ``случайный'' мы придаем условный смысл, принятый в физических науках. 
Мы считаем случайными те явления, которые определяются сложной совокупностью переменных 
причин, трудно поддающихся анализу; к этим явлениям индивидуальный подход невозможен, 
и лишь для их совокупности могут быть установлены определенные закономерности>>. 
Таким образом, термин <<случайный>> в этом понимании  фактически означает
<<непредсказуемый>>, или же такой, в чем  отсутствует закономерность. 

\paragraph{Как учитывать случайные погрешности в данных?}

Прежде всего, сам факт присутствия таких погрешностей в данных можно учесть подходящей 
математической постановкой задачи обработки этих данных. Например, при восстановлении 
функциональных зависимостей (см. гл.~4) вместо задачи интерполяции данных нужно 
рассматривать задачу их аппроксимации (приближения), так как не имеет смысла требовать 
точных равенств значений функции измеренным значениям. Вообще говоря, получение результата 
измерения или наблюдения как решения задачи некоторого математического приближения 
к данным, учитывающей модель исследуемого объекта или явления, является основой 
\emph{аппроксимационных методов} \index{аппроксимационные методы} 
обработки данных.   

Если о природе случайных погрешностей ничего более не известно, то на этом можно 
и нужно остановиться и применять далее аппроксимационные методы. Если о природе 
случайных погрешностей известно что-то определенное, то можно применить для обработки 
данных более изощренные методы, учитывающие дополнительную информацию. 


В настоящее время существуют несколько различных подходов к описанию 
случайности, и некоторые их них чрезвычайно развиты и популярны. Прежде всего, 
это теоретико-вероятностная модель погрешностей, основанная на аппарате математической 
теории вероятности и приводящая к \emph{теоретико-вероятностным методам} обработки 
данных. 
\index{теоретико-вероятностные методы} 
Теоретико-вероятностная модель погрешностей за прошедшие два 
века получила очень большое развитие и распространение, став одним из основных 
инструментов обработки данных. Также следует упомянуть методы нечеткой статистики 
(см.~п.~\ref{FuzzyStatSect}) 
и \emph{эвристические методы} обработки данных,\index{эвристические методы} которые 
применяются при анализе малоизученных явлений, когда отсутствует четкая модель и нет 
представления об искомых характеристиках явления или объекта.  

%Ниже мы конспективно перечислим некоторые из проблем, возникающих при применении   теоретико-вероятностных методов в статистике (<<вероятностная статистика>>), так как именно они чаще всего применяютсянекритично.
% и без опоры на конкретные практические условия, в которых решаются задачи обработки данных. Для краткости мы будем называть их <<вероятностной статистикой>>. 
  \index{вероятностная статистика} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
	\section{Критика вероятностной статистики \\  и альтернативные подходы} 

Развернутая критика вероятностной статистики  содержится в  \cite{MetodikaBook}. Конспективно перечислим основные пункты, по которым в  в  \cite{MetodikaBook} проведено обсуждение.

\paragraph{Статистическая устойчивость.} 
Главной интерпретацией  \index{вероятность} \index{частотная интерпретация}
понятия вероятности является так называемая \emph{частотная интерпретация}, при 
которой вероятность понимается как предел относительной частоты рассматриваемого 
события в серии однородных независимых испытаний (экспериментов и т.\,п.). 

Многие явления окружающего нас мира, в отношении которых применимо слово <<случайный>>, не обладают свойством существования устойчивой относительной 
частоты, так как при росте числа наблюдений она для них не устанавливается. 
Для описания и анализа подобных явлений традиционная теория вероятностей непригодна. 
\index{статистическая устойчивость} 

	\paragraph{Проблема малых выборок.} 
Вероятностные закономерности проявляются как тенденции, которые наиболее ярко видны 
в массовых явлениях.  Фактически
при обработке экспериментальных данных почти всегда стоит вопрос о том, достаточен ли 
объем выборки (количество измерений и т.\,п.) для того, чтобы выводы, получаемые 
на основе теоретико-вероятностной модели погрешностей, имели приемлемую практическую 
достоверность. 

Существующие промышленные стандарты и методики обработки экспериментальных данных (например, \cite{GUM} --- \cite{GOSTDirect}) регламентируют способы работы с выборками размера лишь 
более $15$. При этом результаты обработки выборок размера от $16$ до $50$ рекомендуется 
рассматривать как не очень надежные и сопровождать оговорками, а обработка выборок 
размером не более чем из $15$ измерений стандартами вообще не рассматривается. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    

\paragraph{Неизвестные вероятностные характеристики распределения.} 
Если законы теории вероятностей применимы к анализу погрешностей, то каков конкретный 
вид вероятностных распределений погрешностей? Каковы его числовые характеристики? 
Это непростые вопросы, на которые  не всегда есть ответ.

Например, считается, что типичным законом вероятностного распределения погрешностей 
является нормальное гауссово распределение. Но насколько оно соответствует действительности?  \index{нормальное распределение} 
Известно высказывание А.\,Пуанкаре  \cite{Poincare}: <<$\ldots$все верят в этот закон \ldots\,  потому что экспериментаторы думают, 
что это математическое утверждение, а математики --- что это результат экспериментов>>.  
%Обширная практика XX века и специальные исследования показали, что р
Реальные 
распределения погрешностей измерений в различных ситуациях могут сильно отличаться 
от нормального гауссового.
Для того чтобы выяснить, какое вероятностное распределение имеют 
анализируемые данные, требуется большая дополнительная работа, требующая выборок более 1000 измерений \cite{Orlov2016}. 

Конкретный вид функций распределения случайных величин, которые фигурируют в задачах 
обработки данных, может оказывать существенное влияние на способ их решения. Методология 
максимума правдоподобия для случая нормально распределенных погрешностей данных указывает на 
метод наименьших квадратов, метод наименьших модулей для распределения Лапласа или метод чебышевского сглаживания (минимаксное приближение данных) для равномерно распределенных погрешностей. 


\paragraph{Независимость данных.}  \index{корреляция}\index{независимость} 
Еще одна группа вопросов из этого пункта касается часто используемых в теории 
вероятностей понятий \emph{независимости} и \emph{корреляции} случайных величин. 
Имеют ли данные корреляцию  между собой? Или же они независимы? Многие классические 
результаты вероятностной статистики требуют, как известно,  независимости 
рассматриваемых случайных величин, представляющих результаты измерений, либо 
заданного уровня их корреляции. Проверка этих условий на практике почти невозможна. 

\paragraph{Наличие погрешностей различных типов.} 
В ходе измерений, помимо статистических погрешностей, всегда присутствуют и систематические. Последние могут имет разые источники, их весьма  оценить. Часто эта оценка намного сложнее получения собственно результатов. Но даже если эти оценки получены, встает вопрос: <<Каким образом можно получить совокупную ошибку?>>

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Статистика нечетких данных} 
\label{FuzzyStatSect} 

При нечетком описании результатов измерений и наблюдений мы полагаем, что вместо их 
точных значений нам известны так называемые \emph{функции принадлежности} нечетких чисел, 
возникающих в результате измерений \cite{NguyenKreinWuXiang}. 
\index{нечеткие методы} 
Возникновение нечетких чисел в природных явлениях на примере спектров возбуждения и эмиссии \cite{Javoruk2021} представлено на рис.~\ref{FuzzyNumbers}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\begin{figure}[ht]
	\centering\small  
	\setlength{\unitlength}{1mm} 
	\begin{picture}(110,45) 
%	\put(0,0){\includegraphics[width=50mm]{FuzzyNumber-11.eps}} 
%	\put(47,4){$x$}
%	\put(34,20){$\mu_{1}(x)$}
%	\put(58,0){\includegraphics[width=50mm]{FuzzyNumber-22.eps}} 
%	\put(87,20){$\mu_{2}(x)$} 
%	\put(105,4){$x$}
	\put(25,0){\includegraphics[width=60mm]{ExcitationEmission.png}}
	\end{picture} 
	\caption{Спектры возбуждения-эмиссии как нечеткие числа \cite{Javoruk2021}}
	\label{FuzzyNumbers}  
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{Нечетким множеством} %(см. \cite{DuboisPrade,Zadeh}) 
называется множество $X$, 
образованное элементами произвольной природы, которое дополнено так называемой 
\emph{функцией принадлежности} $\mu: X\to[0, 1]$, значение которой $\mu(x)$ на элементе 
$x\in X$ показывает степень принадлежности $x$ множеству $X$ (рис.~\ref{FuzzyNumbers}). 
У стандартной функции принадлежности множества (называемой также \emph{индикаторной функцией} 
множества) значения могут быть равны только 0 или 1, поэтому допущение для функции $\mu$ 
непрерывного ряда значений из интервала $[0, 1]$ позволяет характеризовать ситуации, когда 
нет уверенности в принадлежности элемента множеству, оперировать количественной мерой 
этой уверенности и строить на этой основе наши выводы и заключения.\index{нечеткое множество} 
\index{функция принадлежности} 

Для построения содержательной теории нечеткого вывода и нечетких неопределенностей 
обычно ограничивают общность функции принадлежности $\mu$, требуя, чтобы она была 
\emph{квазивогнутой}. 
В одномерном случае они являются интервалами. 
Нечеткие множества с квазивогнутыми 
функциями принадлежности называются \emph{нечеткими числами}, и они могут быть 
эквивалентным образом заданы как семейства вложенных друг в друга интервалов, 
которые соответствуют различными уровням принадлежности. \index{нечеткое число}  

%Нечеткое или размытое описание неопределенности является одной из возможных альтернатив вероятностному описанию в тех ситуациях, когда мы не можем разумно задать или определить  вероятностную функцию распределения погрешностей, как какой-то случайной величины. 

Для обработки данных, имеющих нечеткую неопределенность, предложены различные подходы 
(см., например, \cite{NguyenKreinWuXiang}), в частности, 
большое развитие получили методы восстановления зависимостей по нечетким данным \cite{Boukezzoula2021}. 
%Обзор применения различных вариантов методов нечетких множеств и интервальных подходов дан в публикации \cite{Boukezzoula2021}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   



	\section[Место и особенности интервального подхода]%  
{Место и особенности \\* интервального подхода} 


\subsection{Почему интервалы?} \label{NatureIntervals} 

\paragraph{Устройство природы.}
Фундаментальная причина использования интервалов для описания данных состоит в том, что некоторые физические (химические, биологические и 
т.\,п.) величины принципиально не могут быть выражены точечными значениями, а лишь 
интервалами. Поэтому интервалы представляют собой новый удобный тип данных, которым 
уместно дополнить элементарные типы данных, использующиеся в метрологии. 
Большое количество примеров из разных областей науки и техники приведено в \cite{SPbSTU2021}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   

\begin{example}{интервальные веса химических элементов}. 
С 2009 года атомные веса некоторых элементов в Периодической системе  
элементов Д.\,И.\,Менделеева, поддерживаемой Международным союзом теоретической 
	и прикладной химии (ИЮПАК, IUPAC), стали выражаться интервалами \cite{IUPAC}. 
Почти каждый химический элемент представлен в природе смесью своих 
изотопов, т.\,е. разновидностями атомов, сходных по своим химическим свойствам 
(структуре электронных оболочек), но отличающихся массой ядер. Относительная 
доля различных изотопов существенно меняется в зависимости от места и характера 
взятия пробы. Например, в тканях живых организмов преобладают более легкие изотопы 
химических элементов, нежели в неживой природе. Отличаются друг от друга 
относительные доли изотопов элементов на суше и в морях и т.\,п. 
	
Известны изотопы ртути с массовыми числами от 170 до 216 (количество протонов 80, нейтронов --- от 90 до 136). Природная ртуть состоит из смеси семи стабильных изотопов, гистограмма частот изотопов  показана на рис.~\ref{f:HistHg}.
	\begin{figure}[ht] 
		\centering\small
%			\setlength{\unitlength}{0.5mm}
		\begin{tikzpicture}[scale = 0.9]
		%\draw[help lines] (0,0) grid (11,5);
		\draw[->] (0,0) -- (0,4);
		\draw[->] (0,0) -- (10,0);
		\draw (-0.5, 1) node {10 \%};
		\draw (-0.5, 2) node {20 \%};
		\draw (-0.5, 3) node {30 \%};
		\draw[red] (0,0.0155) -- (1,0.0155);
		\draw[red] (1,0.0155) -- (1,0);
		\draw[red] (1,0) -- (2,0);
		\draw[red] (2,0) -- (2,1.004);
		\draw[red] (2,1.004) -- (3,1.004);
		\draw[red] (3,1.004) -- (3,1.694);
		\draw[red] (3,1.694) -- (4,1.694);
		\draw[red] (4,1.694) -- (4,2.314);
		\draw[red] (4,2.314) -- (5,2.314);
		\draw[red] (5,2.314) -- (5,2.314);
		\draw[red] (5,2.314) -- (5,1.317);
		\draw[red] (5,1.317) -- (6,1.317);
		\draw[red] (6,1.317) -- (6,2.974);
		\draw[red] (6,2.974) -- (7,2.974);
		\draw[red] (7,2.974) -- (7,0);
		\draw[red] (7,0) -- (8,0);
		\draw[red] (8,0) -- (8,0.682);
		\draw[red] (8,0.682) -- (9,0.682);
		\draw[red] (9,0.682) -- (9,0);
		\draw (0.6,-0.5) node {196};
		\draw (2.6,-0.5) node {198};
		\draw (4.6,-0.5) node {200};
		\draw (6.6,-0.5) node {202};
		\draw (8.6,-0.5) node {204};
		\draw (10.5,-0.5) node {Масса};
		\draw (10.5,-1) node {изотопа};
		\draw (2,4) node {Распространенность};
		\end{tikzpicture}
		\caption{Распространенность изотопов ртути на Земле}
		\label{f:HistHg}
	\end{figure}
\end{example} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  



\paragraph{Математические причины.}
В чем преимущества и недостатки интервалов в сравнении с другими способами описания 
неопределенности? %Это очень содержательный и важный вопрос, ответ на который мы здесь  кратко наметим. 
Имеется ряд причин, по которым интервалы нужны и важны при обработке данных.  

Во-первых, интервалы являются удобным средством описания и представления типа неопределенностей, часто встречающихся в реальной жизни, --- ограниченных 
по величине неопределенностей. Интервалы проще, чем вероятностные распределения или 
нечеткие множества. 
Интервал --- это <<бесструктурный объект>>, который более сжато описывает неопределенность.
Следствием этой простоты является лучшая развитость теории 
интервального анализа и интервальных вычислительных методов. 

Интервалы 
и интервальные арифметики оказываются  уникальными во многих 
отношениях, в частности, по своим алгебраическим свойствам, простоте и богатству опеределения отношений между объектами и результатами операций.

Далее ---
интервалы являются предельным случаем сумм независимых ограниченных величин. 
В большинстве практических ситуаций погрешность измерения возникает в результате 
накопления и наложения большого количества независимых факторов. 
Оказывается, если некоторая величина есть сумма большого количества малых независимых слагаемых, 
то множество всевозможных значений этой величины близко к интервалу.
Этот результат составляет содержание <<предельной 
теоремы Крейновича>> и ее обобщений \cite{SSharyBook}.
      \index{теорема Крейновича предельная}  

Кроме того, на основе интервалов можно строить составные математические объекты, описывающие аспекты данных и вычислений, которые недоступны в рамках вещественной арифметики, твины и мультиинтервалы. Кратко рассмотрим их в п. \ref{CompositeIntervalTypes}.

\subsection{Статистика интервальных данных} 
\label{InteStatistiSect}    


\textit{Интервальной неопределенностью} называется состояние частичного знания 
о величине, которая не известна точно, но известны нижняя и верхняя границы ее возможных 
значений, или,\index{интервальная неопределенность} иными словами, известен интервал 
возможных значений этой величины. 

В одномерном случае интервалы являются практически наиболее важными ограниченными 
множествами, поэтому другие множества неопределенности используются нечасто. Но 
в многомерном случае множествами возможных значений величины, имеющей ограниченную 
неопределенность, могут быть брусы, многогранники, параллелотопы (зонотопы), 
эллипсоиды и прочие объекты. Их мы относим к объектам интервальной 
статистики и интервального анализа данных. 

Отличительной чертой представляемого подхода является его применимость 
к выборкам любого объема, начиная с нескольких измерений (в предельном случае --- 
одного). Как следствие, проблемы <<малых выборок>>, характерной для вероятностной 
статистики, в интервальном подходе не существует. Это свойство особенно 
ценно, когда технические или экономические причины не позволяют проводить 
много экспериментов. В частности, такова ситуация с алгоритмами обработки результатов 
разрушающих измерений или измерений быстропротекающих процессов в реальном масштабе 
времени. 
Интервальные методы имеют \index{аппроксимационные методы}
\emph{аппроксимационный} характер, т.\,е. осуществляют приближение (аппроксимацию) 
данных в нужном смысле. Следовательно, для их применения  массовость не требуется.   


Развиваемые идеи впервые были оформлены в пионерской работе на данную тему
Л.\,В.\,Канторовича \cite{Kantorovich} и далее неоднократно использовались (или 
даже переоткрывались) разными авторами. 
В то время для обозначения \index{минимаксный подход} 
аналогичных  подходов в математической литературе использовались разные термины --- <<минимаксный подход>> и др. 

Интервальный подход позволяет построить достаточно простую и 
элегантную методику определения выбросов в данных. 
При анализе постоянных величин  целый ряд обобщений традиционных методов, дающих более богатую информацию. 

В задаче восстановления зависимостей 
неопределенности входных и выходных переменных учитываются естественным образом. 
Оценка погрешности результатов получается автоматически в процессе вычислений, не требует дополнительного анализа и напрямую зависит от неопределенности 
данных задачи. 


\paragraph{Принцип соответствия.} 
В методологии науки \textit{принцип соответствия} --- это утверждение, что любая 
новая научная теория должна включать старую теорию и ее результаты как частный 
предельный случай. 	Далее будем использовать принцип соответствия как инструмент проверки адекватности используемых конструкций, понятий и методов обработки данных с интервальными 
неопределенностями, который позволяет отсекать заведомо <<неразумные>>.
\index{принцип соответствия}

