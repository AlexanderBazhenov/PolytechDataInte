
В главе даются определения новых терминов и понятий, которые возникают в связи 
с восстановлением функциональных зависимостей по данным их измерений, 
имеющих интервальную неопределенность. Рассмотрим основные идеи и типичные 
приемы восстановления зависимостей по интервальным данным и возникающие при этом проблемы. 
Подробно исследуется случай простейшей линейной зависимости, но большинство 
построений и рассуждений переносятся на общий нелинейный случай. 

В п.~\ref{FuncProblemDescr} --- \ref{CmptFunCorSect} приведен краткий конспект обсуждения вопроса восстановления зависимостей по интервальным данным, проведенного в книге \cite{MetodikaBook}. Далее приводятся примеры решения конкретных задач.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Постановка задачи} \label{FuncProblemDescr}

Предположим, что величина $y$ является функцией некоторого заданного вида от 
независимых переменных $x_1$, $x_2$, \ldots, $x_m$, т.\,е. 
\begin{equation}
	\label{ParamFunc} 
	y = f(x, \beta), 
\end{equation}
где $x = (x_{1}, \ldots, x_{m})$ --- вектор независимых переменных; $\beta = (\beta_1, \ldots, \beta_l)$ --- вектор параметров функции. 
Имея набор значений переменных $x$  и $y$, нужно найти $\beta_1, \ldots, \beta_l$, которые соответствуют конкретной 
функции $f$ из параметрического семейства \eqref{ParamFunc}. Эту задачу 
называют \emph{задачей восстановления зависимости}, и она будет основным предметом 
рассмотрения.                \index{задача восстановления зависимости} 

Широко используются также другие названия --- <<задача идентификации параметров>>,  
<<задача подгонки данных>>, \index{задача подгонки данных}<<задача подгонки кривой>> 
 <<задача сглаживания данных>> ( Соответствующие англоязычные термины --- identification problem, data fitting  problem, curve fitting problem) и т.\,п. 
 В вероятностной 
статистике рассматриваемую нами задачу называют <<задачей построения регрессии>> или 
<<задачей регрессионного анализа>>, а соответствующая математическая дисциплина 
называется регрессионным анализом. \index{задача сглаживания данных}   \index{задача подгонки  кривой} \index{задача регрессионного анализа}      
Еще одно название задачи --- <<задача построения эмпирических формул>>. 
Исходя из контекста или предметной области, где рассматривается поставленная задача, 
для переменных в рассматриваемой функциональной зависимости используют также 
различные термины. Независимые переменные часто называют \emph{экзогенными}, 
\emph{предикторными} или \emph{входными} переменными, а зависимая переменная 
называется также \emph{эндогенной}, \emph{критериальной} или \emph{выходной} переменной. 

Важнейший частный случай рассматриваемой задачи --- определение параметров линейной 
функции вида 
\begin{equation} 
	\label{LinFunc}
	y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_m x_m , 
\end{equation} 
в которой $x_1$, $x_2$, \ldots, $x_m$ --- независимые переменные; $y$ --- зависимая 
переменная; $\beta_0$, $\beta_1$, \ldots, $\beta_m$ --- некоторые коэффициенты. 
Эти неизвестные коэффициенты должны быть определены из ряда измерений значений $x_1$, 
$x_2$, \ldots, $x_m$ и $y$. 

Результаты измерений неточны, и предполагаеcя что они имеют \emph{ограниченную 
	неопределенность} (см. п.~\ref{InteStatistiSect}), когда известны лишь некоторые 
интервалы, дающие двусторонние границы измеренных значений. Таким образом, результатом 
$i$-го измерения являются такие интервалы $\mbf{x}^{(i)}_{1}$, $\mbf{x}^{(i)}_{2}$, 
\ldots, $\mbf{x}^{(i)}_{m}$, $\mbf{y}^{(i)}$, относительно которых предполагается, 
что истинное значение $x_1$ лежит в пределах $\mbf{x}^{(i)}_{1}$, истинное значение $x_2$ 
лежит в $\mbf{x}^{(i)}_{2}$ и т.\,д. вплоть до $y$, истинное значение которого находится 
в интервале $\mbf{y}^{(i)}$. В целом имеется $n$ измерений, поэтому индекс $i$ может 
принимать значения из множества натуральных чисел $\{ 1,2,\ldots,n \}$. 

Далее для удобства построений и выкладок обозначим номер измерения $i$ не верхним, 
а нижним индексом, который поставим первым при обозначении входов. Таким образом, 
полный набор данных для восстановления зависимости будет иметь вид 
\begin{equation} 
	\label{EmpInData} 
	\begin{array}{ccccc} 
		\mbf{x}_{11}, & \mbf{x}_{12}, & \ldots & \mbf{x}_{1m}, & \mbf{y}_{1}, \\
		\mbf{x}_{21}, & \mbf{x}_{22}, & \ldots & \mbf{x}_{2m}, & \mbf{y}_{2}, \\
		\vdots      &   \vdots      & \ddots &   \vdots      &  \vdots      \\
		\mbf{x}_{n1}, & \mbf{x}_{n2}, & \ldots & \mbf{x}_{nm}, & \mbf{y}_{n}. 
	\end{array}
\end{equation} 
Необходимо найти или как-то оценить коэффициенты $\beta_j$, $j = 0,1,\ldots,m$, 
для которых линейная функция \eqref{LinFunc} наилучшим образом приближала бы 
интервальные данные измерений \eqref{EmpInData}. 

Для обозначения $n\times m$-матрицы, составленной из данных \eqref{EmpInData} 
для независимых переменных, часто используют термины \textit{матрица плана эксперимента} 
или \textit{матрица плана}, которые возникли в теории планирования эксперимента. Интервалы $\mbf{x}_{i1}$, $\mbf{x}_{i2}$, 
\ldots, $\mbf{x}_{im}$, $\mbf{y}_{i}$ будем называть, как и раньше, \textit{интервалами 
	неопределенности $i$-го измерения}. Но кроме них также потребуется обращаться 
ко всему множеству, ограничиваемому в многомерном пространстве $\mbb{R}^{m \, + \, 1}$ этими 
интервалами по отдельным координатным осям. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h!] 
	\centering\small 
	\unitlength=1mm
	\begin{picture}(90,40)
		\put(5,0){\includegraphics[width=80mm]{LineBoxes.png}}
		\put(0,38){\mbox{\small $\mbf{y}$}} 
		\put(86,2){\mbox{\small  $\mbf{x}$}} 
	\end{picture}
	\caption{Иллюстрация задачи восстановления линейной
		зависимости по данным с интервальной неопределенностью}
	\label{UncertBoxesPic}
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{definition} 
	\textsl{Брусом неопределенности} $i$-го измерения функциональной зависимости будем 
	называть интервальный вектор-брус $(\mbf{x}_{i1}, \mbf{x}_{i2}, \ldots, \mbf{x}_{im}, 
	\mbf{y}_{i}) \subset \mbb{R}^{m+1}$, $i = 1,2,\ldots,n$, образованный $i$-й строкой 
	таблицы данных \eqref{EmpInData}.          \index{брус неопределенности измерения} 
\end{definition} 

Таким образом, каждый брус неопределенности измерения зависимости является прямым 
декартовым произведением интервалов неопределенности независимых переменных и зависимой 
переменной. На рис.~\ref{UncertBoxesPic} на плоскости $0xy$ наглядно показаны брусы 
неопределенности измерений и график линейной функции, которую восстанавливаем. 
Далее рассматриваем данные \eqref{EmpInData} как уже существующие и не обсуждаем их получение, выбор или оптимизацию. 



\section[Накрывающие и ненакрывающие измерения и выборки]% 
{Накрывающие и ненакрывающие \\* измерения и выборки} 
\label{CoverNCoverSect} 
Как и ранее, в п.~\ref{CoverMeasrSect}, принимаем следующее 

\begin{definition}   
	Брус неопределенности измерения функциональной зависимости называется \textsl{накрывающим}, 
	если он гарантированно содержит истинные значения измеряемых величин входных и выходных 
	переменных зависимости.       \index{накрывающий брус} 
\end{definition} 

Условимся называть брус неопределенности измерения \emph{ненакрывающим}, если нельзя утверждать, что он наверняка содержит 
истинное значение. Иными словами, ненакрывающий брус может включать 
истинное значение, а может и не включать его.        \index{ненакрывающий брус}

\textit{Накрывающей выборкой} будем называть совокупность измерений, т.\,е. 
выборку, в которой\index{накрывающая выборка} \emph{доминирующая} часть измерений 
являются накрывающими. Ненакрывающей называем выборку, большинство составляющих которую 
измерений могут не содержать истинных значений измеряемой зависимости. 

По поводу ненакрывающей выборки можно сказать то же самое, что и по поводу 
ненакрывающего бруса. Удобно называть этим термином выборку, для большинства измерений который не гарантирировано свойство накрытия истинного значения. Итак, \emph{ненакрывающая выборка} --- это выборка, для измерений которой мы не можем утверждать, что они наверняка 
являются накрывающими.              \index{ненакрывающая выборка} 

Для визуализации интервальных данных аналогично традиционному точечному случаю 
используют \emph{диаграммы рассеяния}. В традиционном понимании диаграмма рассеяния 
используется в статистике и анализе данных для визуализации значений двух переменных 
в виде облака точек на декартовой плоскости и позволяет оценить наличие или 
отсутствие корреляции и других взаимосвязей между двумя переменными. На диаграмме 
рассеяния для интервальных данных каждое интервальное наблюдение отображается в виде 
бруса (бруса неопределенности). При отсутствии неопределенности по одной из переменных, 
брусы наблюдений могут превращаться в одномерные вертикальные или горизонтальные отрезки 
(<<ворота>> для случая накрывающих измерений).\index{диаграмма рассеяния} Примерами 
диаграмм рассеяния могут служить рис.~\ref{UncertBoxesPic} и \ref{UncCoridsPic}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Информационное множество задачи} 
\label{InformSetSect} 


Существует большое количество стандартных подходов к решению задачи 
восстановления зависимостей для обычных точечных данных. В практической обработке данных широко используются метод наименьших квадратов, метод наименьших модулей, чебышевское (минимаксное) сглаживание. Все эти методы основаны 
на  нахождении минимума какой-либо количественной меры отклонения конструируемой 
функции от приближаемых данных, которую часто называют \emph{функционалом качества}. 
\index{функционал качества} Ищут набор параметров, который доставляет минимум этой 
мере отклонения, т.\,е. функционалу качества.  

Для интервальных данных реализация описанного выше общего принципа становится 
затруднительной, поскольку не вполне ясно, как именно выбирать отклонение функции 
от приближаемых интервальных данных. Это особенно характерно для накрывающих 
измерений и накрывающих выборок, которые представляют собой множества возможных 
значений измеряемой величины. 

Для %более тонкого и детального 
анализа ситуации, который %, в конце концов, 
приведет  к фундаментальному понятию информационного множества задачи восстановления 
зависимости, необходимо начать рассмотрение задачи с самого базового уровня. 
Итак, пусть имеется набор экспериментальных данных 
\begin{equation} 
	\label{EmpReData} 
	\begin{array}{ccccc} 
		x_{11}, & x_{12}, & \ldots & x_{1m}, & y_{1}, \\ 
		x_{21}, & x_{22}, & \ldots & x_{2m}, & y_{2}, \\ 
		\vdots  & \vdots  & \ddots &  \vdots & \vdots \\ 
		x_{n1}, & x_{n2}, & \ldots & x_{nm}, & y_{n} 
	\end{array}
\end{equation} 
и формула для функциональной зависимости, зависящая от параметров \eqref{ParamFunc}. 

Мы подставляем данные в формулу для зависимости \eqref{LinFunc} и получаем для каждого 
измерения одно уравнение вида 
\begin{equation*} 
	f( x_{i}, \beta) = y_{i},  
\end{equation*} 
где $x_i = (x_{i1}, x_{i2}, \ldots, x_{im})$. В целом в результате этой процедуры 
возникает система таких уравнений, решив которую относительно $\beta$, мы найдем параметры зависимости. 

В традиционном случае обработки точечных данных полученная система уравнений является, 
как правило, несовместной и решений в обычном смысле не имеет. При подстановке любого набора параметров 
$\beta$ в уравнения \eqref{ParamFunc}, получаем 
ненулевое расхождение левой и правой частей, которое в традиционном регрессионнном 
анализе называется \emph{остатком} \index{остаток} 
\begin{equation*} 
	f( x_{i}, \beta) - y_{i} = \varepsilon_{i}.  
\end{equation*} 
Поэтому вместо обычных решений системы рассматривают решения в обобщенном 
смысле --- \emph{псевдорешения}, т.\,е. векторы,\index{псевдорешения} 
на которых достигается минимальное отклонение левой и правой частей системы уравнений:
\begin{equation*} 
	\hat{\beta} = \arg \min_{\beta}	\| \varepsilon_{i} \|. %\longrightarrow \min.  
	\end{equation*}
Фактически задача нахождения 
псевдорешения --- это и есть задача минимизации функционала качества в какой-то конкретной норме, в которой онявляется величиной вектора остатков измерений. 

Таким образом, имеется два общих подхода к нахождению параметров зависимости 
по эмпирическим данным. На основе вида искомой функциональной зависимости и обрабатываемых данных  составляется 
\begin{itemize} 
	\item %[(I)]  
		система уравнений и находится ее решение; 
	\item %[(II)]  
		задача минимизации отклонения функции от эмпирических данных 
	и находится ее решение. 
\end{itemize} 

В случае точечных данных преимущественное значение имеет второй способ, так как система 
уравнений почти всегда не имеет обычных решений. Но для интервальных данных ситуация меняется на противоположную. 

Что следует считать решением задачи восстановления зависимости по интервальным 
данным \eqref{EmpInData}? 

Очевидно, что функцию вида \eqref{ParamFunc} или \eqref{LinFunc} нужно считать точным 
решением задачи восстановления искомой зависимости, если ее график проходит через все 
брусы неопределенности данных. В случае точечных данных эта идеальная ситуация почти 
никогда не реализуется и неустойчива к малым возмущениям в данных. Но для данных 
с существенной интервальной неопределенностью прохождение графика функции через брусы 
данных \eqref{EmpInData} может реализовываться, и оно устойчиво к возмущениям в данных. 
Кроме того,  брусы неопределенности данных \eqref{EmpInData}, в отличие от бесконечно малых и бесструктурных точек, получают структуру, и потому нужно различать, как именно проходит график функции через эти брусы. 

В интервальном случае, подставляя данные в равенство \eqref{ParamFunc} для искомой функциональной зависимости, мы получим интервальную систему уравнений. Ее решением будет вектор оценки параметров восстанавливаемой зависимости 
\eqref{ParamFunc}. При этом разрешимость системы интервальных уравнений 
не является исключительным событием, тогда как определение задачи минимизации отклонения функциональной зависимости от данных сталкивается с трудностями. 

В соответствии с терминологией, введенной в п.~\ref{InfoSetSect}, \emph{информационным множеством} задачи восстановления зависимости 
нужно называть множество значений параметров зависимости, совместных с данными в каком-то 
определенном смысле.\index{информационное множество} Информационное множество задачи восстановления функциональной зависимости по интервальным 
данным --- это множество решений интервальной системы уравнений, неравенств и т.\,п. 
условий, вытекающих из постановки задачи восстановления зависимостей, т.\,е. вида 
функциональной зависимости и обрабатываемых данных. 

Почему понятие информационного множества столь важно при обработке интервальных 
измерений?  Дело в том, что именно информационное множество учитывает специальный 
характер накрывающих интервальных измерений, когда они являются не просто большими 
<<раздувшимися точками>>, а еще включают и возможные точные значения измеряемых 
величин. 

В оптимизационном подходе момент учета накрытия/ненакрытия отодвигается на второй план, а потому его нужно сочетать с проверкой существования непустого информационного множества задачи. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Прогнозный коридор и коридор \\ совместных зависимостей} 
\label{CmptFunCorSect} 


Определение параметров функциональной зависимости производится, как правило, для того, 
чтобы затем найденную формулу использовать для предсказания значений зависимости 
в других интересующих точках ее области определения или вне нее. Такое предсказание 
будет осуществляться с некоторой погрешностью, вызванной неопределенностями данных, 
неоднозначностью процедуры восстановления и т.\,п. 

	Пусть дана задача восстановления функциональной зависимости вида $y = f(x,\beta)$, 
где областью определения независимой переменной $x$ является множество $X$, а 
значения зависимой переменной $y$ принимаются во множестве $Y$. Будем называть 
\emph{прогнозным коридором}\index{прогнозный коридор} для задачи восстановления 
зависимостей по интервальным данным многозначное отображение $\varPi : X\to Y$, 
которое каждой точке области определения $X$ восстанавливаемой зависимости 
сопоставляет множество возможных значений отображений, которые, в рамках 
рассматриваемой модели, могут принимать функциональные зависимости, 
восстановленные по данным задачи. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb] 
		\centering\small 
\unitlength=1mm 
%	\includegraphics[width=80mm]{FuncCorridor.eps} 
\begin{picture}(100,40)
	\put(20,0){\includegraphics[width=70mm, height=40mm]{FuncTubeQuadSect.png}}
	\put(64,-2){$x^\ast$} 
	\put(90,-2){$x$} 
	\put(36,35){$\mbf{y}$} 
\end{picture}
	\caption{Коридор совместных зависимостей и его сечение
	для какого-то значения аргумента $x^\ast$} 
	\label{FuncTubePic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Если информационное множество задачи восстановления зависимостей непусто, то обычно 
оно задает целое семейство зависимостей, совместных с данными задачи, которое имеет 
смысл рассматривать вместе как единое целое. 
Как следствие, возникает необходимость рассматривать вместе, единым 
целым, множество всех функций, совместных с интервальными данными задачи восстановления 
зависимости. Мы будем будем называть его \textit{коридором совместных зависимостей} 
(см. рис.~\ref{FuncTubePic}). 

В литературе использовались также другие термины  --- <<трубка>> совместных зависимостей (имеет происхождение в теории 
управления), <<полоса>> или  <<слой неопределенности>>, <<коридор неопределенности>> и т.\,п. 
Строгое определение коридора 
совместных зависимостей может быть дано на основе математического понятия многозначного 
отображения. Для 
произвольных множеств $X$ и $Y$ \emph{многозначным отображением} $F$ из $X$ в $Y$ 
называется соответствие (правило), сопоставляющее каждой точке $x\in X$ непустое 
подмножество $F(x)\subset Y$, называемое \emph{значением}, или \emph{образом} $x$. 
\index{многозначное отображение} 

\begin{definition} 
	Пусть в задаче восстановления зависимостей информационное множество $\varOmega$ 
	параметров зависимостей $y = f(x,\beta)$, совместных с данными, является непустым. 
	\textsl{Коридором совместных зависимостей} рассматриваемой задачи называется 
	многозначное  отображение $\varUpsilon$, сопоставляющее каждому значению 
	аргумента $x$ множество 
	\begin{equation*} 
		\varUpsilon(x) \  = \;\bigcup_{\beta\in\varOmega} f(x,\beta). 
	\end{equation*} 
\end{definition} 

Значение $\varUpsilon(\tilde{x})$ коридора совместных зависимостей при каком-то 
определенном аргументе $\tilde{x}$ (сечение коридора) --- это множество 
$\,\cup_{\beta\in\varOmega}\, f(\tilde{x},\beta)$, образованное всевозможными 
значениями, которые принимают на этом аргументе функциональные зависимости, 
совместные с интервальными данными измерений. 

Это множество описывает неопределенность 
прогноза на аргументе $\tilde{x}$. Его нужно уметь вычислять или каким-либо 
образом оценивать. В частности, необходимо знать внешние оценки интервала 
\begin{equation*} 
	\Bigl[\;\min_{\beta \, \in \,  \varOmega}\, f(\tilde{x},\beta),\,  
	\max_{\beta \, \in \,  \varOmega}\, f(\tilde{x},\beta)\,\Bigr].   
\end{equation*} 
В ряде задач необходимо также знать внутреннюю оценку коридора совместных 
зависимостей. 
На рис.~\ref{FuncTubePic} изображен коридор совместных зависимостей в задаче 
восстановления нелинейной зависимости, но для рассматриваемого линейного 
случая границы коридора совместных зависимостей являются кусочно-линейными 
(см.  рис.~\ref{DataParamCorridorEpsilon150}). С примерами использования 
коридора совместных зависимостей можно ознакомиться в \cite{Kumkov2010}. 

	Понятие прогнозного коридора шире понятия коридора совместных 
зависимостей. Если информационное множество задачи пусто, то и о коридоре 
совместных зависимостей не имеет смысл говорить, но, как правило, оценку 
параметров при этом все равно необходимо получить, и какая-то функциональная 
зависимость будет построена. У этого решения задачи некоторая неопределенность 
все равно присутствует, а потому имеет смысл и прогнозный коридор. 

	\section{Выбросы и их выявление} 
\label{RegrOutlSect} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Общие идеи выявления выбросов} 

Понятие <<выброс>> в статистике и анализе данных, как правило, определяется неформально, поскольку  критерии для признания измерения выбросом 
лежат вне формальной математической постановки задачи анализа данных.
Существует много подходов, в которых общим является указание на нарушение измерением-выбросом согласованности, ожидаемой для большинства 
наблюдений выборки по отношению к конкретной математической модели. 

Формальным индикатором согласованности данных, 
модели и априорной информации является непустота информационного множества, соответствующего 
задаче. Пустота информационного множества свидетельствует о наличии тех или иных 
противоречий между данными и моделью. Поиск причин появления противоречий, а также 
выбор путей их преодоления — процесс неформальный. 

\vspace{-2mm}
\paragraph{Статус измерений.} 
\label{MeasrStatusSect} \index{статус измерений}

О влиянии некоторого интервального измерения $s = (x,\mbf{y})$ на модель, построенную 
по выборке $\eus{S}_{n}$, можно судить на основе того, в каком взаимоотношении находятся 
информационные множества $\varOmega(s)$ и $\varOmega(\eus{S}_{n})$. Такая характеризация 
полезна как для новых измерений ($s \notin \eus{S}_{n}$), так и для измерений, уже 
входящих в выборку ($s \in \eus{S}_{n}$). 

Измерения, добавление которых к выборке не приводит к модификации модели 
($\varOmega(\eus{S}_{n}) = \varOmega(\eus{S}_{n} \cup s)$), именуются %(см. \cite{PomeRodionova}) 
\textit{внутренними}, изменяющие же модель 
($\varOmega(\eus{S}_{n}) \supset \varOmega(\eus{S}_{n} \cup s)$) --- \textit{внешними}. 
В каждом из этих классов измерений дополнительно выделяют специальные подклассы 
--- \textit{граничные} измерения и \textit{выбросы} соответственно . 

\textit{Граничными} называют измерения, определяющие какой-либо фрагмент границы 
информационного множества. Очевидно, это свойство имеет смысл рассматривать для 
наблюдений, принадлежащих выборке $\eus{S}_{n}$, по которой сконструированы модель 
и информационное множество $\varOmega(\eus{S}_{n})$. Подмножество всех граничных 
наблюдений в $\eus{S}_{n}$ играет особую роль, поскольку оно является минимальной 
подвыборкой, полностью определяющей модель. Удаление неграничных наблюдений из выборки 
не изменяет модель.     \index{граничное измерение} 

Среди внешних измерений особым образом выделяют \textit{выбросы} (промахи). Построение 
модели по выборке, пополненной таким наблюдением, приводит не только к уменьшению 
информационного множества, а к его пустоте  ($\varOmega(\eus{S}_{n} \cup s) 
= \varnothing$), к разрушению модели. \index{выброс} 

Анализ 
взаимоотношений информационных множеств $\varOmega(\eus{S}_{n})$ и $\varOmega(\eus{S}_{n} 
\cup s)$ или $\varOmega(\eus{S}_{n})$ и $\varOmega(s)$ можно заменить выяснением отношений 
интервала неопределенности $\mbf{y}$ анализируемого измерения $s = (x, \mbf{y})$ и 
интервального прогнозного значения рассматриваемой модели в той же точке $\varUpsilon 
(x; \eus{S}_{n})$. На рис.~\ref{ObservStatus} анализируемые измерения показаны  
линиями, а соответствующие им интервалы прогнозов --- широкими линиями, их ширина не имеет содержательного смысла, а лишь упрощает восприятие наложенных 
друг на друга интервалов. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\begin{figure}[h!]
	\centering\small  
	\setlength{\unitlength}{1mm} 
	\begin{picture}(80,40)
%	\put(0,0){\includegraphics[width=60mm]{ObservStatuses.pdf}} 
	\put(0,0){\includegraphics[width=80mm, height=40mm]{DataStatus.png}}
	\end{picture} 
	\caption{Интервальные наблюдения с различными статусами: \textit{внутреннее} 
		($n=1$), \textit{граничные} ($n=2$), \textit{внешние} ($n=3$), 
		\textit{строго внешнее} ($n=5$), \textit{выбросы} ($n=4$)} 
	\label{ObservStatus}  
\end{figure}  



\emph{Внутреннее} интервальное измерение $s = (x,\mbf{y})$ полностью содержит в себе 
прогнозный интервал, оцененный с помощью модели $\varUpsilon(x;\eus{S}_{n})$, или, 
иными словами, пересечение двух этих интервалов совпадает с прогнозным: $\mbf{y} 
\cap \varUpsilon(x;\eus{S}_{n}) =  \varUpsilon(x;\eus{S}_{n})$. Будучи перестроенной 
по выборке, пополненной подобным измерением, модель не претерпит изменений, поскольку 
соответствующее ей информационное множество окажется внутри ограничения, порожденного 
добавленным внутренним измерением, следовательно, пересечение с ним не изменится. 
Коридор совместных зависимостей при этом также сохранит прежний вид. 

Если \emph{внешнее} интервальное измерение и соответствующий ему интервал прогноза имеют 
непустое пересечение, то результирующий интервал сужается по сравнению с прогнозным:  
\begin{equation*}
\mbf{y} \cap \varUpsilon(x; \eus{S}_{n}) \subset \varUpsilon(x;\eus{S}_{n}).
\end{equation*}
Это означает, что добавление внешнего измерения в модель уменьшит информационное 
множество задачи и коридор совместных зависимостей. Получение пустого множества 
в пересечении свидетельствует о том, что измерение, возможно, является выбросом 
по отношению к используемой модели. 

В анализе данных вводят специальные величины \emph{размаха} (плечо, англ. --- high leverage)\index{размах}  и \emph{относительного остатка} (относительное остаточное отклонение,  относительное смещение, англ. --- relative residual).
Размах и остаток позволяют установить статус наблюдения посредством проверки выполнения некоторых простых неравенств \cite{MetodikaBook}. 
Следует отметить, что характеризация наблюдений в терминах размахов и остатков не зависит 
от размерности входной переменной $x$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection[Варьирование неопределенности измерений]% 
{Варьирование величины \\*  неопределенности измерений} 
\label{VaryUncertSect}            

Один из приемов выявления выбросов в задаче построения зависимости по интервальным
наблюдениям основан на интерпретации выбросов как наблюдений с недооцененной величиной 
неопределенности \cite{Zhilin2007, ZhilinDiss}. Закономерным шагом в этом случае 
становится поиск некоторой минимальной коррекции величин неопределенности интервальных 
наблюдений, необходимой для обеспечения совместности задачи построения зависимости. 
Если величину коррекции каждого интервального наблюдения 
$\mbf{y}_i = [\mathring{y}_i - \epsilon_i, \mathring{y}_i + \epsilon_i]$ выборки 
$\eus{S}_{n}$ выражать коэффициентом его уширения $w_i \geq 1$, а общее изменение 
выборки характеризовать суммой этих коэффициентов, то минимальная коррекция выборки 
в виде вектора коэффициентов $w^* = (w_1^*, \dots, w_n^*)$, необходимая для совместности 
задачи построения  зависимости $y = f(x,\beta)$, может быть найдена решением задачи 
условной оптимизации 
\begin{equation} 
\label{MinSumW_Subj} 
\text{найти} \quad \min_{w,\, \beta}\;\Sigma_{i \, = \, 1}^n w_{i} 
\end{equation}
при ограничениях
\begin{equation} 
\label{MinSumW_Constr} 
\left\{ \ 
\begin{gathered}
\mathring{y}_i - w_i \, \epsilon_i \leq f(x_i,\beta) 
\leq \mathring{y}_i + w_i \, \epsilon_i,    \\[2pt]   
w_i \geq 1, 
\end{gathered}
\qquad 
i = 1,\dots,n. 
\right. 
\end{equation}

Результирующие значения коэффициентов $w_i^*$, строго превосходящие единицу, указывают 
на наблюдения, которые требуют уширения интервалов неопределенности для обеспечения 
совместности данных и модели. Именно такие наблюдения заслуживают внимания при анализе 
на выбросы. Значительное количество подобных наблюдений может говорить либо 
о неверно выбранной структуре зависимости, либо о том, что величины неопределенности 
измерений занижены во многих наблюдениях (например, в результате неверной оценки 
точности измерительного прибора). 

Следует отметить значительную гибкость языка неравенств. Он дает возможность 
переформулировать и расширять систему ограничений \eqref{MinSumW_Constr} для учета 
специфики данных и задачи при поиске допустимой коррекции данных, приводящей 
к разрешению исходных противоречий. Например, если имеются основания считать, 
что величина неопределенности некоторой группы наблюдений одинакова и при коррекции 
должна увеличиваться синхронно, то система ограничений (\ref{MinSumW_Constr}) может 
быть пополнена равенствами вида 
\begin{equation*} 
w_{i_1} = w_{i_2} = \cdots = w_{i_K}, 
\end{equation*} 
где $i_1, \dots, i_K$ --- номера наблюдений группы.
В случае, когда в надежности каких-либо наблюдений исследователь уверен полностью, 
при решении задачи (\ref{MinSumW_Subj}), (\ref{MinSumW_Constr}) соответствующие 
им величины $w_i$ можно положить равными единице, т.е. запретить варьировать их 
неопределенность. 

Задача поиска коэффициентов масштабирования величины неопределенности 
(\ref{MinSumW_Subj})--(\ref{MinSumW_Constr}) сформулирована для 
распространенного случая уравновешенных интервалов погрешности и подразумевает 
синхронную подвижность верхней и нижней границ интервалов неопределенности 
измерений $\mbf y_i$ при сохранении базовых значений интервалов $\mathring{y}_i$ 
неподвижными. При необходимости постановка задачи легко обобщается. Например, если 
интервалы наблюдений не уравновешены относительно базовых значений 
(то есть $\mbf y_i = [\mathring{y}_i - \epsilon^{-}_i,\, \mathring{y}_i + 
\epsilon^{+}_i ]$ и $\epsilon^{-} \neq \epsilon^{+}$), 
то границы интервальных измерений можно варьировать независимо, масштабируя 
величины неопределенности $\epsilon^{-}_i$ и $\epsilon^{+}_i$ с помощью отдельных 
коэффициентов $w_i^{-}$  и $w_i^{+}$: 
\begin{equation} 
\label{MinSumW_Subj_Nonsym} 
\text{найти} \quad \min_{w^{-},\,w^{+},\,\beta}\;\Sigma_{i=1}^n (w_i^{-} + w_i^{+}) 
\end{equation}
при ограничениях
\begin{equation} 
\label{MinSumW_Constr_Nonsym} 
\left\{ \ 
\begin{gathered}
\mathring{y}_i - w_i^{-} \, \epsilon^{-}_i \leq f(x_i,\beta) \leq 
\mathring{y}_i + w_i^{+} \, \epsilon^{+}_i, \\[2pt] 
w_i^{-} \geq 1, \\[2pt]  
w_i^{+} \geq 1, 
\end{gathered}
\qquad i = 1,\dots,n. 
\right. 
\end{equation}

Для линейной по параметрам $\beta$ зависимости $y = f(x,\beta)$ задача 
(\ref{MinSumW_Subj}), (\ref{MinSumW_Constr}) представляет собою задачу линейного 
программирования, для решения которой широко доступны программы в составе библиотек на различных языках программирования, в виде стандартных 
процедур систем компьютерной математики, а также в виде интерактивных подсистем 
электронных таблиц. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section[Случай точных измерений входных переменных]% 
{Случай точных измерений \\* входных переменных} 
\label{ExactInputSect} 

Важнейшим и часто встречающимся частным случаем рассмотренной задачи является 
ситуация, когда независимые (экзогенные, предикторные, входные) переменные $x_1$, 
$x_2$, \ldots, $x_m$ измеряются точно, и вместо телесных брусов неопределенности 
измерений (как на рис.~\ref{UncertBoxesPic}) имеем отрезки прямых $(x_{i1}, x_{i2}, 
\ldots, x_{im}, \mbf{y}_{i})$, $i = 1,2,\ldots,n$, параллельные оси зависимой 
(эндогенной, критериальной, выходной) переменной (см. рис.~\ref{UncCoridsPic}). 
Впервые такая постановка задачи была рассмотрена в работе Л.В.\,Канторовича 
\cite{Kantorovich}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!htb] 
		\centering\small 
	\unitlength=1mm
\begin{picture}(60,40)
	\put(5,0){\includegraphics[width=55mm]{LineGates.png}}
	\put(3,30){\mbox{\small $\mbf{y}$}} 
	\put(60,2){\mbox{\small  $\mbf{x}$}} 
\end{picture}
	\caption{Частный случай задачи восстановления линейной 
	зависимости по неточным данным, когда входные 
	переменные измеряются точно}
	\label{UncCoridsPic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Популярность задачи восстановления зависимости в такой постановке определяется несколькими факторами.
В широком классе случаев входные переменные определены точно (номер измерения, задание входной переменной  в целочисленной арифметике) или с очень малой погрешностью. Погрешность может быть неизвестна, и непонятно, как ее оценивать. Измерения могут быть настолько грубыми, что погрешности во входных данных заведомо пренебрежимы. 

Отсутствие неопределенности значений независимых переменных приводит к кардинальному 
упрощению математической модели. Брусы неопределенности измерений зависимости, 
введенные ранее, схлопываясь по независимым переменным, превращаются в \emph{отрезки 
	неопределенности}.\index{отрезок неопределенности} Для решения и полного 
исследования этого частного случая, начиная с работы \cite{Kantorovich}, предложено 
большое количество эффективных вычислительных методов. 

Линейная зависимость \eqref{LinFunc} \emph{совместна} 
(согласуется) с интервальными данными измерений, если ее график проходит через все 
отрезки неопределенности, задаваемые интервалами измерений выходной переменной $y$, 
как это изображено на рис.~\ref{UncCoridsPic}). Подобное понимание совместности 
(согласования) является прямым обобщением того понимания совместности, которое 
традиционно для неинтервального случая и используется, к примеру, в постановке задачи 
интерполяции. 

Подставляя в зависимость \eqref{LinFunc} данные для входных переменных $x_1$, $x_2$, 
\ldots, $x_m$ в $i$-м измерении и требуя включения полученного значения в интервалы
$\mbf{y}_{i}$, получим 
\begin{equation} 
	\label{LinIneqs} 
	\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_m x_{im} \in\mbf{y}_{i}, 
	\qquad  i = 1,2,\ldots,n.  
\end{equation}  
С одной стороны, это интервальная система линейных алгебраических уравнений 
\begin{equation*} 
	\arraycolsep=2pt 
	\left\{ \ 
	\begin{array}{ccccccccccc}
		\beta_0 &+& x_{11}\beta_1 &+& 
		x_{12} \beta_2 &+& \ldots &+& x_{1m}\beta_m &=& \mbf{y}_{1}, \\[3pt] 
		\beta_0 &+& x_{21}\beta_1 &+& 
		x_{22} \beta_2 &+& \ldots &+& x_{2m}\beta_m &=& \mbf{y}_{2}, \\[3pt] 
		\vdots &&  \vdots && \vdots && \ddots && \vdots && \vdots                  \\[3pt]  
		\beta_0 &+& x_{n1}\beta_1 &+& 
		x_{n2} \beta_2 &+& \ldots &+& x_{nm}\beta_m &=& \mbf{y}_{n}, 
	\end{array} 
	\right. 
\end{equation*} 
у которой интервальность присутствует только в правой части. С другой стороны, 
система \eqref{LinIneqs} равносильна системе \eqref{LinIneqSys} 
\begin{equation} 
	\label{LinIneqSys} 
	\arraycolsep=2pt 
	\left\{ \ 
	\begin{array}{ccccc}
		\un{\mbf{y}}_{1} & \leq & \beta_0 + \beta_1 x_{11} + 
		\beta_2 x_{12} + \ldots + \beta_m x_{1m} & \leq & \ov{\mbf{y}}_{1}, \\[3pt] 
		\un{\mbf{y}}_{2} & \leq & \beta_0 + \beta_1 x_{21} + 
		\beta_2 x_{22} + \ldots + \beta_m x_{2m} & \leq & \ov{\mbf{y}}_{2}, \\[3pt] 
		\vdots & \vdots &   \ddots & \vdots & \vdots \\[3pt] 
		\un{\mbf{y}}_{n} & \leq & \beta_0 + \beta_1 x_{n1} + 
		\beta_2 x_{n2} + \ldots + \beta_m x_{nm} & \leq & \ov{\mbf{y}}_{n}. 
	\end{array} 
	\right. 
\end{equation} 
Это система двусторонних линейных неравенств относительно неизвестных параметров 
$\beta_0$, $\beta_1$, $\beta_2$, \ldots, $\beta_m$, решив которую, мы можем найти 
искомую линейную зависимость. Множество решений системы неравенств \eqref{LinIneqSys} 
является информационным множеством параметров восстанавливаемой зависимости
для рассматриваемого случая. 

Для $i$-го двустороннего неравенства из системы \eqref{LinIneqSys} множество решений 
--- это полоса в пространстве $\mbb{R}^{m \, + \, 1}$ параметров $(\beta_0, \beta_1, \ldots,
\beta_m)$, ограниченная с двух сторон гиперплоскостями с уравнениями  \index{полоса} 
\begin{align*} 
	\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_m x_{im} = \un{\mbf{y}}_{i},
	\\[3pt] 
	\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_m x_{im} = \ov{\mbf{y}}_{i}.  
\end{align*} 
Множество решений системы неравенств \eqref{LinIneqSys} является пересечением $n$ 
штук таких полос, отвечающих отдельным измерениям. Можно рассматривать эти полосы 
как информационные множества отдельных измерений. На рис.~\ref{UncertStripesPic} 
изображено формирование множества решений системы неравенств \eqref{LinIneqSys} 
для случая двух параметров (то есть $m = 2$) и $n = 3$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb]
	\centering\small   
	\unitlength=1mm 
	\begin{picture}(80,40)
%		\put(0,0){\includegraphics[width=80mm]{UncertStripes.eps}}
		\put(10,0){\includegraphics[width=60mm]{BandsIntersection.png}}
		\put(70,2){$\beta_0$}
		\put(12,37){$\beta_1$} 
	\end{picture}
	\caption{Образование информационного множества параметров
	\, линейной зависимости (ограничено красной линией) \\ 
	\, для случая точных входных переменных }
	\label{UncertStripesPic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

В целом множество решений системы линейных алгебраических неравенств \eqref{LinIneqSys} 
является выпуклым многогранным множеством в пространстве $\mbb{R}^{m \, + \, 1}$. Распознавание 
его пустоты или непустоты, а также нахождение какой-либо точки из него являются
задачами, сложность которых ограничена полиномом от их размера. Существуют эффективные и хорошо разработанные вычислительные 
методы для решения этих вопросов и для нахождения оценок множества решений. 
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   

\subsection{Пример решения задачи для случая точных измерений входных переменных} \label{ExactInputSectExample}

Рассмотрим конкретный пример решения задачи для случая точных измерений входных переменных,
для которого используется аппарат линейного программирования для достижения совместности информационного множества \cite{Zhilin2005}, \cite{Zhilin2007}. 
Технологическая схема вычислений представлена в виде блокнота на ресурсе С.\,И.\,Жилина \cite{IntervalAnalysisExamples}.

В целом при восстановлении зависимости по интервальным измерениям нужно решить следующие задачи:\\
--- построение модели данных согласно п.~\ref{ParErrorModel}; \\
%	\item 
---	построение функциональной модели;\\
%	\item 
--- определение параметров модели;\\
%	\item 
--- построение информационного множества и коридора совместности;\\
%	\item 
--- построение прогноза внутри и за пределами экспериментальных данных;\\
%	\item 
--- нахождение граничных точек множества совместности.
%	\item обработка данных на предмет выделения выбросов.
%\end{itemize}

\begin{example}{Пример восстановления зависимости}
При измерении параметров шагового двигателя  была получена зависимость положения вала от номера шага \cite{Ermakov2021}. 
	\begin{figure}[htb] 
		\centering\small 
		\unitlength=1mm
	\begin{picture}(100,40)
				\put(15,0){\includegraphics[width=60mm]{EncoderStepData.png}}
		\put(-5,40){\mbox{\small Данные}} 
		\put(-5,37){\mbox{\small измерений}}
		\put(77,5){\mbox{\small Номер}} 
		\put(77,2){\mbox{\small измерения}} 
	\end{picture} 
		\caption{Зависимость положения вала двигателя от номера шага. }
		\label{EncoderStepData}
	\end{figure}
Для облегчения восприятия, выберем 10 значений замеров из числа данных, представленных на рис.~\ref{EncoderStepData}. Конкретно выбрано 10 первых нечетных значений для статических положений вала двигателя и вычтена аддитивная константа, отвечающая числу поворотов вала. Получившиеся результаты сведены в таблицу \ref{TableDataEncoderpart}.

	\begin{table}[h!tb]
		\begin{center}
			\begin{tabular}{ c | c | c| c| c| c | c| c| c| c| c } 
			%	\hline
				Номер  & 1   & 2  & 3  & 4 & 5  & 6 & 7 & 8 & 9 & 10 \\
				\hline
				Данные  & 388 & 737  & 951  & 1354 & 1756 & 1970 & 2399 & 2801 & 3204 & 3606 \\
			%	\hline			
			\end{tabular}
		\end{center}
		\caption{Подвыборка из данных рисунка~\ref{EncoderStepData}}
		\label{TableDataEncoderpart}
	\end{table}
	
В данном случае имеем дело с типичной ситуацией при работе с приборами, выдающими цифровые значения измерений.	Данные энкодера доступны в виде целых значений и паспортная неопределенность измерений равна $0,5^{\circ}$ \cite{Ermakov2021}
при дискретности измерений 12 бинарных разрядов на $360^{\circ}$. Таким образом, имеем тип погрешности данных согласно \eqref{ErrorNOB}
		\begin{equation*} 
	\mbf{y} = \mathring{y} + \mbf{\epsilon}, 
	\end{equation*}
	$\mathring{y}$ --- значение, выданное измерителем, а интервал погрешности примем в виде 
		\begin{equation*}
где	\mbf{\epsilon} = [-\epsilon, \epsilon]; \quad \epsilon = \lceil 0.5 \cdot \tfrac{2^{12}}{360} \rceil = 6.
	\end{equation*}
	Здесь $\lceil \cdot  \rceil$ означает округление в большую сторону.
	
Например, для первой строчки в табл.~\ref{TableDataEncoderpart} имеем 
$	\mbf{y}_1 = [382, 394].$	
Реально погрешность, как увидим, существенно выше, и включает много факторов, о части которых недостаточно сведений, и можно судить только об их совокупности  по результату измерений.
	
\vspace{-2mm}
\paragraph{Точечная оценка параметров регрессии.} \label{PointRegressionEstimate}
	
В качестве первого подхода к проблеме проведем точечную оценку параметров регрессии. 
Пусть  модель задается в классе линейных функций
	\begin{equation} \label{e:linmodel}
		y = \beta_1 + \beta_2 x,
	\end{equation}
где	$x$ --- номер измерения в выборке,  $y$ --- угол поворота вала двигателя.
	
Для согласования с данными поставим задачу оптимизации и решим методами линейного программирования \cite{MetodikaBook}. В соотвествии с подходом к варьированию величины неопределенности п.~\ref{VaryUncertSect} поставим задачу \eqref{MinSumW_Constr} в виде
\begin{equation} 
	\left\{ \ 
	\begin{gathered}
		\m \mbf{y}_i-w_i \cdot \r \mbf{y}_i \leq X \beta \leq 	\m \mbf{y}_i + w_i \cdot \r \mbf{y}_i, \quad i=1, m, \nonumber \\
	\sum_{i=1}^m w_i \longrightarrow \min  \nonumber \\
 w_i \geq 0, \quad i=1,2, \ldots m, \nonumber \\
 w, \beta =? \label{L1opt} 
	\end{gathered}
	\right. 
\end{equation}
Здесь $X$ --- матрица $m \times 2$, в первом столбце которой элементы, равные 1, во втором --- значения $x_i$. 	
В качестве значений середины и радиуса возьмем $\m \mbf{y}_i = y_i$ и $\r \mbf{y}_i=1$.
	
Решив поставленную задачу с помощью программных средств на языке {\tt Octave}, доступных на ресурсе \cite{IntervalAnalysisExamples}, получим уравнение регрессионной в виде \index{Octave}
\begin{equation} \label{linmodel_ZLP}
		 y = -11,7 +   352,3 \cdot x.
\end{equation}
	
	\begin{figure}[h!] 
		\centering\small 
		\unitlength=1mm
		\begin{picture}(100,50)
			\put(10,0){\includegraphics[width=75mm]{L1optimization.png}}
			\put(-7,45){\mbox{\small Данные}} 
			\put(-7,42){\mbox{\small измерений}}
			\put(81,5){\mbox{\small Номер}} 
			\put(81,2){\mbox{\small измерения}} 
	\end{picture}
		\caption{Регрессия с оценкой по норме $L_1$. Данные табл.~\ref{TableDataEncoderpart}}
		\label{L1optimization}
	\end{figure}
	
Вектор весов $w$ радиусов отдельных замеров приведен в \eqref{weightL1}. Вместе с рис.~\ref{L1optimization}, высокая неоднородность значений $w$ свидетельствует о разной по величине степени отклонении данных от регрессионной прямой на разных участках оси абсцисс
	\begin{equation}\label{weightL1}
	w = \left\lbrace 
	 4,8, 	4,8, 17,7, 8,7, 0,17, 22,3,	9,0, 0,17, 8,8, 17,7
	\right\rbrace .
	\end{equation}
	
Наибольшее отклонение от регрессионной прямой и максимальные веса, необходимые для достижения совместности, имеет измерение в середине рассматриваемого участка.

\vspace{-2mm}	
\paragraph{Интервальная оценка параметров регрессии.} \label{IntRegressionEstimate}
Приступим к интервальной оценке параметров регрессии. Ясно, что при достаточно высокой погрешности данных выборка станет \emph{накрывающей} или, по крайней мере совместной, согласно  п.~\ref{CoverMeasrSect}. 
	
Для этого необходимо приписать данным какие-то дополнительные погрешности, помимо погрешностей квантования. Значения компонент вектора $w$ несут индивидуальную информацию о каждом измерении. Такая информация обладает высокой степенью избыточности, и желательно ее заменить на более экономное представление.	Имеет смысл в качестве первой оценки реалистичной погрешности данных взять близкую к максимальному значению  $\varepsilon w$ в \eqref{weightL1}.
Итак, примем для всех измерений значение $$\r \mbf{y}_i : = \varepsilon = \max_{i} \varepsilon_{i} w_i \simeq 150.$$ 

\vspace{-2mm}	
\paragraph{Информационное множество параметров $\mbf{I}$.}	
Определим  интервальные параметры регрессии по методике \cite{IntervalAnalysisExamples}. На  рис.~\ref{InformationSetEpsilon150} изображено информационное множество п.~\ref{InformSetSect} параметров модели \eqref{e:linmodel} --- сдвигов и наклонов регрессионной прямой. Оно ограничено многоугольником и выделено заливкой.
	\begin{figure}[h!] 
		\centering %\small 
		\unitlength=1mm
		\begin{picture}(100, 48)
			\put(5,43){$\beta_1$}
			\put(15,0){\includegraphics[width=70mm]{InformationSetEpsilon150.png}}
			\put(87,5){$\beta_0$} 
		\end{picture}
		\caption{Информационное множество $\mbf{I}$, погрешность $\varepsilon=150$}
		\label{InformationSetEpsilon150}
	\end{figure}
Также на рис.~\ref{InformationSetEpsilon150} приведены различные точечные оценки. 
Они определены в результате вычисления максимальной диагонали, центра тяжести, методом наименьших квадратов, точечной регрессией.	
Для заданного значения погрешности данных все точечные оценки содержатся в информационном множестве.

\vspace{-2mm}	
\paragraph{Коридор совместности $\varUpsilon$.} 
На рис.~\ref{DataParamCorridorEpsilon150} изображены диаграмма рассеяния данных и коридор совместности п.~\ref{CmptFunCorSect} для полученных выше параметров модели регрессии для заданной модели погрешности данных.
	\begin{figure}[h!] 
	\centering %\small 
	\unitlength=1mm
	\begin{picture}(100,48)
		\put(15,0){\includegraphics[width=70mm]{DataParamCorridorEpsilon150.png}}		\put(-5,43){\mbox{\small Данные}} 
		\put(-5,40){\mbox{\small измерений}}
		\put(87,5){\mbox{\small Номер}} 
		\put(87,2){\mbox{\small измерения}} 
	\end{picture}
%		\includegraphics[width=80mm]{DataParamCorridorEpsilon150.png} 
		\caption{Диаграмма рассеяния и коридор совместности $\varUpsilon$, $\varepsilon=150$. }
		\label{DataParamCorridorEpsilon150}
	\end{figure}
	
Также дана прямая регрессии по параметрам, соотвествующим центру тяжести множества, показанного на  рис.~\ref{InformationSetEpsilon150}. 
Для значения независимой переменной, равному 6, эта прямая касается границ коридора совместности. 
	\begin{figure}[h!] 
	\centering %\small 
\unitlength=1mm
\begin{picture}(100,40)
		\put(20,0){\includegraphics[width=55mm]{AnglePointEpsilon150.png}}
	\put(0,37){\mbox{\small Данные}} 
	\put(0,34){\mbox{\small измерений}}
	\put(80,5){\mbox{\small Номер}} 
	\put(80,2){\mbox{\small измерения}} 
\end{picture}
		\caption{<<Излом>> множества $\varUpsilon$. }
		\label{AnglePointEpsilon150}
	\end{figure}	
То есть в этом месте имеется <<излом>> множества $\varUpsilon$. 

\vspace{-2mm}	
\paragraph{Прогноз значений выходной переменной.}
Важнейшим назначением регрессионной модели является предсказание значений выходной переменной для заданных значений входной.
	
С помощью информационного множества $\mbf{I}$ для построенной модели 
\begin{equation} \label{e:ModelData1}
		\mbf{y}(x) = [-138,4,   91,7 ] + [336,4,    376,4] \cdot x
\end{equation}
можно получить прогнозные значения выходной переменной в точках эксперимента. В \eqref{e:ModelData1} для величин параметров регресссии ($\mbf{\beta}_0, \mbf{\beta}_1$) взяты величины интервальной облочки $\ih \mbf{I}$ см. рис.~\ref{InformationSetEpsilon150}. 
	
Ценность модели заключается в возможности ее примененения для предсказания выходной переменной в точках, где измерения не производились.	Для иллюстрации приведем прогнозы в одной точке внутри диапазона $x=5$ и двух точках за его границами $x=-1, \ x=15$. 
Графически результат расчета представлен на рис.~\ref{PredictionEpsilon150}.
	\begin{figure}[h!] 
	\centering %\small 
	\unitlength=1mm
	\begin{picture}(100,50)
			\put(10,0){\includegraphics[width=70mm]{PredictionEpsilon150.png}}
		\put(-5,48){\mbox{\small Данные}} 
		\put(-5,45){\mbox{\small измерений}}
		\put(84,5){\mbox{\small Номер}} 
		\put(84,2){\mbox{\small измерения}} 
	\end{picture}
	\caption{Прогноз значений внутри и  вне интервала имеющихся данных, погрешность данных $\varepsilon=150$}
	\label{PredictionEpsilon150}
\end{figure}

Численные результаты расчетов представлены в табл.~\ref{TableForecast1}.
	\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c|c|c|c|c|c|}
				\hline	
				$i$ & $x_i$ & $\m \mbf{y}$ & $\r \mbf{y}_i$ & $\un{\mbf{y}}_i$ &  $\ov{\mbf{y}}_i$ \\
				%	\hline
				%	~ & мВ & мВ & мВ & мВ &  мВ \\	
				\hline	
				1 & -1 & -380 & 148 & -515  &   -245 \\
				2 & 5 & 1724 & 56 & 1689 & 1780 \\
				3 & 15 & 5323 & 185 & 5318 & 5508 \\
				\hline
			\end{tabular}	
		\end{center}
		\caption{Прогноз измерений по модели \eqref{e:ModelData1}. }
		\label{TableForecast1}
	\end{table}
Как видно, чем более удалена точка прогноза от области данных, тем больше предсказываемая погрешность.
	
\vspace{-2mm}		
\paragraph{Уточнение модели погрешности данных.}
Итак, при значении погрешности данных, равной $\varepsilon=150$, получены согласованные оценки параметров линейной модели данных \eqref{e:ModelData1}. 
Напомним, что величина $\varepsilon$ выбрана с запасом из соображений обеспечения заведомого  согласования данных и линейной модели.
Посмотрим, что произойдет при попытке уменьшить эту неопределенность. Пусть $\varepsilon=100.$
	
Определим интервальные параметры регрессии. На  рис.~\ref{InformationSetEpsilon110} приведено новое информационное множество сдвигов и наклонов регрессионной прямой. 
\begin{figure}[h!] 
		\centering %\small 
		\unitlength=1mm
		\begin{picture}(100,45)
			\put(15,0){\includegraphics[width=65mm]{InformationSetEpsilon110.png}}
			\put(10,42){$\beta_1$}
			\put(82,5){$\beta_0$} 
		\end{picture}
		\caption{Информационное множество, погрешность данных $\varepsilon=110$}
		\label{InformationSetEpsilon110}
\end{figure}
	
Множество параметров линейной модели на рис.~\ref{InformationSetEpsilon110} существенно меньше аналогичного множества  рис.~\ref{InformationSetEpsilon150}. Конкретные значения ширин параметров $\beta$ приведены в табл.~\ref{TableWidbeta}.
	\begin{table}[h]
		\begin{center}
			\begin{tabular}{|c|c|c|}
					\hline
				$\varepsilon$ & $\w \mbf{\beta}_1$ &$\w \mbf{\beta}_2$ \\
				\hline
				100	 & $\simeq 29$ & $\simeq 4$ \\
				\hline				
				150	 & $\simeq 250$ & $\simeq 38$\\
				\hline
			\end{tabular}
			\caption{Размеры множества параметров линейной модели данных}
			\label{TableWidbeta}
		\end{center}
	\end{table}
Согласование становится модели и данных в таких условиях весьма проблематично. В частности, оценка точечных параметров модели методом наименьших квадратов (черный квадратик на рис.~\ref{InformationSetEpsilon110}  ) находится за пределами $\mbf{I}$. 
	
Уменьшение информационного множества приводит к сужению коридора совместности параметров модели.
На рис.~\ref{DataParamCorridorEpsilon110} приведены диаграмма рассеяния данных и коридор совместности параметров модели регрессии $\varUpsilon$ для заданной погрешности данных.
	
	\begin{figure}[h!] 
	\centering %\small 
	\unitlength=1mm
		\begin{picture}(100,45)
			\put(15,0){\includegraphics[width=65mm]{DataParamCorridorEpsilon110.png}}
			\put(-5,45){\mbox{\small Данные}} 
			\put(-5,42){\mbox{\small измерений}}
			\put(87,5){\mbox{\small Номер}} 
			\put(87,2){\mbox{\small измерения}} 
		\end{picture}
		\caption{Диаграмма рассеяния и коридор совместности $\varUpsilon$, погрешность данных $\varepsilon=110$ }
		\label{DataParamCorridorEpsilon110}
	\end{figure}
	
Коридор совместности $\varUpsilon$ представляет собой узкую полосу, проходящую через крайние значения нескольких брусов. Конкретно коридор совместности касается множества вершин брусов 
\begin{equation} \label{e:Boundary}
		\Omega_B =\{\un{\mbf{y}}_1, \ov{\mbf{y}}_6, \un{\mbf{y}}_{10} \}.    
\end{equation}
	
Как было отмечено ранее, в середине графика для измерения 6 имеется излом. 
Дальнейшее уменьшение 	$\varepsilon$ приводит к пустоте множества параметров. При $\varepsilon=100$ выборка становится \emph{ненакрывающей}.
	
В п.~\ref{RegrOutlSect} дана классификация данных выборки по отношению к формированию информационного множества и введено понятие \textit{граничных} измерений информационного множества. 	Подмножество всех граничных наблюдений в $S_n$ играет особую роль, поскольку оно является \emph{минимальной подвыборкой, полностью определяющей модель}. 
В рассмотренном примере это множество $\Omega_B $ \eqref{e:Boundary}.	Удаление неграничных наблюдений из выборки не изменяет модель.  
\end{example}
	
В приведенном примере продемонстрирована технология обработки выборки с точными значениями входных переменных и \emph{неизвестной заранее погрешностью данных}. 
Выбором модели погрешностей выборка была сделана \emph{накрывающей}. Инструментом служил аппарат линейного программирования. Далее было показано, что при занижении  погрешности данных происходит уменьшение информационного множества вплоть до его пустоты.

Помимо техники линейного программирования, можно проводить вычисления посредством нахождения максимума функционала специального вида, что носит название <<метод максимума согласования>> \cite{SharysJCT2013}. Программно метод поддерживается свободно распространяемыми программами, доступными  на сайте \cite{SharySoftware}. 
Для данных табл.~\ref{TableDataEncoderpart} нахождение неизвестных $\beta_0, \beta_1$ с использованием программы {\tt tolsolvty} \cite{SharySoftware} для прямой \eqref{e:linmodel} дает уравнение регресиии
\begin{equation}\label{linmodel_Tol}
	y = -72,4 +   357,6 \cdot x.
\end{equation}
Прямая для \eqref{linmodel_Tol} весьма близка к прямой на рис.~\ref{L1optimization} по \eqref{linmodel_ZLP}.

	\section[Общий случай задачи восстановления зависимостей]%
{Общий случай задачи восстановления зависимостей} 
\label{GenIDataFitSect} 

	Рассмотрим  случай, когда неопределенность присутствует как в измерениях 
значений зависимой переменной, так и в измерениях значений аргументов 
(рис.~ \ref{UncertBoxesPic}). Это может быть вызвано различными причинами, отчасти рассмотренными в \cite{SPbSTU2021} . 
Например, существенно неточное измерение входных переменных происходит 
в ситуациях, когда они должны устанавливаться в течение значительного времени.
 Тогда их уместно выразить интервалами, а не точечными значениями. 


Отметим, что этот класс задач сложнее, чем рассмотренный выше случай точных измерений входных переменных п.~\ref{ExactInputSect}. Эта сложность 
относится как к постановке задачи, так и методам решения. Развернутое, хотя и не исчерпывающее всех аспектов проблемы, обсуждение проведено в \cite{MetodikaBook}.  

Если выборка измерений независимых переменных и зависимой переменной --- накрывающая, то  
\begin{equation*} 
	\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_m x_{im} \in\mbf{y}_{i}, 
	\qquad  i = 1,2,\ldots,n, 
\end{equation*} 
где все $x_{i1}$ могут принимать значения из соответствующих интервалов $\mbf{x}_{i1}$, 
$i = 1,2,\ldots,n$, $j = 1,2,\ldots,m$. Как следствие, получаем интервальную систему 
линейных алгебраических уравнений (ИСЛАУ), сходную с \eqref{LinIneqSys}.

Это формальная запись, означающая совокупность обычных (точечных) систем линейных 
алгебраических уравнений того же размера и с теми же неизвестными переменными, 
у которых коэффициенты и правые части лежат в предписанных им интервалах 
(см. \cite{SSharyBook}). Восстановление параметров линейной зависимости можно 
рассматривать как решение выписанной интервальной системы 
уравнений. 

В случае присутствия погрешностей как в измерениях аргумента, так и в измерениях 
зависимости, множество параметров зависимостей, совместных (согласующихся) с данными, 
характеризуются новыми свойствами. Множества решений отдельных интервальных уравнений 
уже не являются полосами в пространстве $\mbb{R}^n$, вроде тех, что изображены 
на рис.~\ref{UncertStripesPic}. Их конкретный вид 
зависит от того, какой смысл вкладывается в понятие совместности (согласования) 
параметров и данных, т.\,е. от того, какое множество решений ИСЛАУ взято в качестве 
информационного множества. 

Понятие совместности (согласования) параметров и данных 
должно быть расширено и переосмыслено. В обычном неинтервальном случае результаты 
измерений --- это точки, и прохождение через них 
графика функциональной зависимости описывается двумя значениями --- <<да>> 
или <<нет>>. Для брусов неопределенности имеются различные варианты прохождения 
через них графика зависимости. Брус неопределенности 
измерений $(\mbf{x}_{i1}, \mbf{x}_{i2}, \ldots, \mbf{x}_{im}, \mbf{y}_{i})$ является 
прямым декартовым произведением интервалов по различным осям координат, и эти оси 
имеют разный смысл: интервалы $\mbf{x}_{i1}$, $\mbf{x}_{i2}$, \ldots, $\mbf{x}_{im}$ 
соответствуют входным переменным, а интервал $\mbf{y}_{i}$ --- выходной переменной. При этом 
становится важным, как именно проходит график восстанавливаемой зависимости через 
брусы неопределенности измерений (рис.~\ref{BoxLineIxPic}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb]
	\centering\small 
	\unitlength=1mm 
	\begin{picture}(82,33)
%		\put(0,0){\includegraphics[width=82mm]{BoxLineIntersect.eps}} 
		\put(15,0){\includegraphics[width=50mm]{LineBoxesVar.png}} 
		\put(70,2){$\mbf{x}$} 
		\put(9,30){$\mbf{y}$} 
	\end{picture} 
	\caption{Различные способы пересечения линии с брусом неопределенности измерения зависимости }
	\label{BoxLineIxPic}  
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

	Функциональную зависимость называют \textit{слабо совместной} с интервальными данными, 
если ее график проходит через каждый брус неопределенности измерений хотя бы для одного 
значения аргумента. График зависимости пересекает брусы 
неопределенности, но как именно --- неважно (рис.~\ref{BoxLineIxPic}, средний брус), 
достаточно не менее одной точки пересечения. 

Функциональную зависимость назовем \textit{сильно совместной} с интервальными данными, 
если ее график проходит через каждый брус неопределенности измерений для любого значения 
аргумента из интервалов неопределенности входных переменных. График зависимости целиком содержится в коридорах, задаваемых интервалами выходной 
переменной при всех значениях входных переменных из соответствующих им интервалов 
(рис.~\ref{BoxLineIxPic}, левый брус). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb]
	\centering\small 
	\unitlength=1mm 
	\begin{picture}(67,32)
%		\put(0,0){\includegraphics[width=67mm]{WeakStrongCmp.eps}}
		\put(0,0){\includegraphics[width=65mm, height=30mm]{WeakStrongCmp.png}}		\put(15,25){\mbox{\begin{tabular}{c}Слабосовместная\\[-1pt] зависимость\end{tabular}}} 
		\put(41, 8){\mbox{\begin{tabular}{c}Сильносовместная\\[-1pt] зависимость\end{tabular}}} 
	\end{picture} 
	\caption{Линейные зависимости с разными типами согласования с данными.}
	\label{WeakStrongPic}  
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

На рис.~\ref{BoxLineIxPic} правый брус соответствует ситуации, когда 
график зависимости лежит в коридоре, задаваемом интервалом входной переменной $\mbf{x}$, 
при любых значениях выходной переменной $y$ из соответствующего ей интервала $\mbf{y}$. 

Сильная совместность при интервальной неопределенности данных означает, что выходная величина остается 
в пределах измеренного для нее интервала вне зависимости от  конкретных значений входных переменных внутри их интервала. 
В работах С.\,П.\,Шарого, например, в \cite{SSharyJCT2017}, показано, что требование сильной совместности параметров и данных 
позволяет обрабатывать различные сложные случаи восстановление зависимостей 
по широким и существенно <<перекрывающимся>> интервальным данным. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

В настоящее время предложено несколько методов восстановления линейных 
зависимостей: 
метод центра неопределенности \cite{ZhilinDiss, Zhilin2005}, метод максимума совместности 
(максимума согласования) \cite{SharysJCT2013, SSharyIzvAN2017, SSharyPLab2020}, 
метод парциальных информационных множеств \cite{Kumkov2010, Kumkov2013} и др. 

\vspace{-2mm}
\paragraph{Восстановление зависимостей по ненакрывающим выборкам.}

В случае восстановления зависимостей по ненакрывающим выборкам не может быть универсальных подходов.
В  \cite{MetodikaBook} предлагается в виде критерия, по которому можно определять пригодность восстанавливаемой зависимости, использовать \emph{расстояние до брусов} данных.
Там же обсуждаются возникающие сложные, иногда парадоксальные ситуации при обработке  ненакрывающих выборок.
В целом в данной области еще немного результатов, и это передний фронт исследований в области анализа данных с интервальной неопределенностью \cite{ZvyaginSShary}.

\vspace{-2mm}
\paragraph{Восстановление нелинейных зависимостей.}

Восстановление нелинейной зависимости в принципиальном плане не отличается от линейного случая. 
Пример применения интервального подхода с использованием полиномов второго порядка содержится в работе \cite{Kovalenko2021}.
