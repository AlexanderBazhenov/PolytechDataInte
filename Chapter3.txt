
	\section[Выборка измерений и интервалы их неопределенности]% 
{Выборка измерений \\*  и интервалы их неопределенности} 

\emph{Постоянная величина} --- это величина, которая в рассматриваемом 
процессе сохраняет свое значение неизменным. Например, рост человека не меняется 
заметно в процессе его измерения, и поэтому может считаться постоянной величиной, 
хотя на протяжении жизни человека рост, конечно же, непостоянен. 
\index{постоянная величина} 

Пусть имеется выборка измерений некоторой величины
\begin{equation}
	\label{ISample} 
	\mbf{x}_{1}, \mbf{x}_{2}, \ \ldots, \ \mbf{x}_{n}, 
\end{equation}                                 
или кратко $\{\,\mbf{x}_{k}\}_{k \, = \, 1}^n$, где $k$ --- номер измерения; $\mbf{x}_k$ 
--- интервальный результат измерения, полученный, к примеру, с помощью какой-либо из процедур, 
описанных в предыдущих главах. Таким образом, согласно терминологии интервального 
анализа рассматриваемая выборка --- это вектор интервалов или интервальный вектор 
$\mbf{x} = (\mbf{x}_{1}, \mbf{x}_{2}, \ \ldots, \ \mbf{x}_{n})$. Число $n$ --- размерность 
вектора данных --- будем называть \emph{длиной выборки} (или объемом 
выборки).\index{длина выборки} По интервальным результатам измерений или наблюдений 
требуется найти оценку  для интересующей нас величины. 
\index{задача измерения постоянной величины} 

{\bf Табличные данные}
	В качестве источника данных для ряда примеров будем использовать  \cite{Pgamma1992}. В Табл.~\ref{TableData}	воспроизведена часть данных из \cite{Pgamma1992}. 
	 
\begin{table}[h!]
\begin{center}
\begin{tabular}{| c | c | c | }
\hline
Номер замера & Peak &   {\tt std}  Peak \\ % &  BG &   {\tt std} BG \\
\hline
1 &	- 4,4 & 2,7 \\ % & 4,2 & 6,7 \\
2 & - 3,4 & 1,9 \\ % & - 3,2 &	4,8 \\
3 & - 6,9 & 2,4 \\ % & 12,1 &	9 \\
$\vdots$ & $\vdots$ & $\vdots$ \\ % & 12,1 &	9 \\
%				4 &	- 1,2 & 2,4 \\ % & 12,4 &	7,2 \\
%				5 &	- 1,0 & 2,7 \\ % & 9,4 & 5,1 \\
%				6 &	- 10,8 &	3,5 \\ % &1	& 12,4 \\
%				7 &	- 10,2 &	2,8 \\ % &- 0,6 &	6,1 \\
8 &	- 6,3 &	2 \\ % &	3,9 &	4,3\\
$\vdots$ & $\vdots$ & $\vdots$ \\ % & 12,1 &	9 \\
%				9 &	- 10,4 &	4,1 \\ % &	10,3 &	10\\
%				10 & 0,6& 3,4 \\ % & - 4,8 & 10,6\\
%				11 &- 1,8 &	2 \\ % &	4,6&	4,2\\
12 &- 6,6 & 2,1	\\ % &- 5,7&4,6\\
13 &- 4,9 &2,1 \\ % &	13 &3 \\
14 &- 6,0 &	2,4 \\ % & 8,4	&4,6\\
15 &- 4,0 & 2,7 \\ %	& 10,6 &5,5\\
\hline	
\end{tabular}
\end{center}
\caption{Данные табл. 1  для величины $\delta \times 10^{5}$ \cite{Pgamma1992}}
\label{TableData}
\end{table}

Для наглядного представления выборки часто чертят образующие ее интервалы в виде 
графика, изображенного на рис.~\ref{ScatPlotPic}, который по статистической традиции 
называют \emph{диаграммой рассеяния} (см. также рис.~\ref{EncloConstPic} и 
~\ref{NEnclConstPic}). 
Можно повернуть картинку и представлять \index{диаграмма рассеяния} 
интервалы данных горизонтально (см. рис.~\ref{f:ModelData2hor}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(90,55)
		\put(0,0){\includegraphics[width=80mm]{PgammaPhNoTickLabels.png}}
		\put(5,55){$\mbf{x}$}	
		\put(13,3){$1$} 
		\put(25,3){\ldots}
		\put(40,3){$k$} 
		\put(55,3){\ldots}
		\put(68,3){$n$} 
		\put(64,10){\mbox{\small Номер измерения}} 
	\end{picture}
	\caption{Диаграмма рассеяния интервальных измерений постоянной величины}
	\label{ScatPlotPic} 
\end{figure} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

Значения $\r\mbf{x}_k$, $k = 1,2,\ldots,n$, показывают величины интервальной 
неопределенности отдельных измерений выборки. Величину 
неопределенности всей выборки характеризует вектор радиусов $$\r\mbf{x} = 
(\r\mbf{x}_{1}, \r\mbf{x}_{2}, \ \ldots, \ \r\mbf{x}_{n})$$. 
Но часто такая детальность не требуется  в представлении неопределенности выборки, 
а нужна какая-либо одна величина, которая агрегированным образом представляет данную 
неопределенность. В этом случае можно взять какую-либо норму вектора $\r\mbf{x}$.

По аналогии с традиционной метрологией будем называть измерения выборки 
\textit{равноширинными}, если неопределенность всех этих измерений одинакова, т.\,е. 
$\r\mbf{x}_k = r = \const$, $k = 1, \ \ldots, \ n$. Напротив, \textit{неравноширинными} 
(разноширинными) называем измерения, в которых величина неопределенности $\r\mbf{x}_k$ 
может меняться в зависимости от измерения выборки, $k = 1, \ \ldots, \ n$. Фактически эти 
термины  означают  <<имеющие равную неопределенность>>  и  <<имеющие неодинаковые 
неопределенности>>. \index{равноширинные измерения}\index{неравноширинные измерения} 

Информационным множеством в случае оценивания единичной постоянной величины по выборке 
интервальных данных будет также интервал, который будем называть \emph{информационным 
	интервалом}. Неформально говоря, это интервал, содержащий значения оцениваемой величины, 
которые совместны с измерениями выборки (согласуются с данными этих измерений). 
Но конкретный смысл, вкладываемый в понятия <<совместные>> или <<согласующиеся>>, будет 
различен для разных ситуаций. В частности, он зависит от того, является ли выборка  
интервальных данных накрывающей или нет. \index{информационный интервал}


	\section{Обработка накрывающих выборок} 
\label{CoverSampleProcSect} 


Если истинное значение величины содержится во всех интервалах измерений выборки
$\{ \ \mbf{x}_{k} \ \}_{k \, = \ 1}^n$, то оно должно принадлежать также пересечению этих 
интервалов. Следовательно, уточненным интервалом принадлежности истинного значения 
может быть объединение
\begin{equation} 
\label{IXInterval} 
\mbf{I}\; = \;\bigcap_{1 \, \leq k \, \leq n} \mbf{x}_{k}. 
\end{equation} 
Это и будет информационным множеством $\mbf{I}$ оценки измеряемой физической величины 
(см. рис.~\ref{EncloConstPic}) --- \emph{информационный	интервал}. Явные выражения для его левой (нижней) и правой (верхней) границ выражены 
следующими формулами:                            \index{информационный интервал}
\begin{equation}
\label{LoUpBounds} 
\un{\mbf{I}}\, = \,\max_{1\leq k\leq n} \,\un{\mbf{x}}_{k};
\hspace{23mm} 
\ov{\mbf{I}}\, = \,\min_{1\leq k\leq n} \,\ov{\mbf{x}}_{k}. 
\end{equation}                                     

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h!]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(90,60)
		\put(0,0){\includegraphics[width=90mm]{ExampleCover.png}}
		\put(75,10){\mbox{\small Номер измерения}} 
		\put(25,45){\mbox{\small $\mbf{x}_1$}}
		\put(52,35){\mbox{\small $\mbf{x}_k$}}
		\put(79,43){\mbox{\small $\mbf{x}_N$}}
%		\put(2,35){\mbox{\small $\r \mbf{I} \left\lbrace  \right. $}}	
		\put(15,19){\mbox{\small $ \mbf{I}$}}
		\put(37,19){\mbox{\small \ldots }}
		\put(65,19){\mbox{\small \ldots}}
		\put(0,35){\mbox{\small $\r \mbf{I}  $}}
		\put(10,31){\vector(0,1){9}}	
		\put(10,40){\vector(0,-1){9}}		
		\put(0,30){\mbox{\small $\m \mbf{I}$}}	
		\put(7,60){\mbox{\small $ \mbf{x}$}}
		\put(7,26){\mbox{\small $\check{x}$}}		
		\put(23,3){\mbox{\small 1}}
		\put(37,3){\mbox{\small \ldots }}
		\put(65,3){\mbox{\small \ldots}}
		\put(51,3){\mbox{\small $k$}}
		\put(78,3){\mbox{\small $N$}}
	\end{picture}
	\caption{Обработка накрывающей выборки} 
	интервальных измерений величины 
	\label{EncloConstPic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  


В силу сделанного допущения о том, что выборка накрывает истинное значение величины, 
имеем  $\un{\mbf{I}}\leq\ov{\mbf{I}}$. При этом заслуживает внимания предельный случай совместной 
выборки, когда $\un{\mbf{I}} = \ov{\mbf{I}} = x^{\ast}$. Тогда выборка совместна, но  на пределе  совместности, и информационный интервал $\mbf{I}$ вырождается  в точку. 

Если известен некоторый априорный интервал возможных значений оцениваемой постоянной  
величины $\mbf{I}_\text{апр} = [\un{\mbf{I}}_\text{апр}, \ov{\mbf{I}}_\text{апр}]$, 
который должен гарантированно содержать ее, то границы результирующего интервала 
\eqref{IXInterval} могут быть уточнены пересечением 
\begin{equation}
\label{ImpIXInterval}
\mbf{I} = \mbf{I} \,\cap \,\mbf{I}_{\text{апр}}. 
\end{equation} 
Отметим, что априорный интервал $\mbf{I}_\text{апр}$ может задавать одностороннее 
ограничение, если он имеет вид $[\un{\mbf{I}}_\text{апр}, +\infty]$ или 
$[-\infty, \ov{\mbf{I}}_\text{апр}]$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

На практике часто необходимо работать не с интервалами интересующей нас величины --- 
\eqref{IXInterval} или \eqref{ImpIXInterval}, а с некоторой точечной оценкой $\check{x}$. 
Все точки информационного интервала равноценны друг другу, поэтому точечную 
оценку $\check{x}$ можно выбирать произвольно (см. рис.~\ref{EncloConstPic}). 
Тем не менее имеет смысл взять из интервала некоторое точечное значение, которое 
представляет его наилучшим образом. В качестве такой величины можно использовать, 
к примеру, его \textit{центральную оценку} $x_{\text{c}}$, 
\begin{equation}
\label{MidEstim}
x_{\tt c} \; = \;\m\mbf{I}\; = \;\tfrac{1}{2}\,\bigl(\un{\mbf{I}} + \ov{\mbf{I}}\bigr). 
\end{equation} 
Cередина интервала обладает определенной 
оптимальностью, являясь точкой, которая наименее удалена от других точек этого 
интервала.             \index{центральная оценка} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{example}{Обработка накрывающей выборки.}
Выберем из данных табл.~\ref{TableData} накрывающую подвыборку. Это замеры с номерами
\begin{equation} \label{CoverSubSet}
 \{ 1, 2, 3, 8, 12, 13, 14, 15 \}.
\end{equation}
Диаграмма рассеяния выборки \eqref{CoverSubSet}
приводится на рис.~\ref{ScatPlotPicCover}. Также на  рисунке приведены оценки границы информационного множества \eqref{LoUpBounds}.
Численно оценки границ 'этого информационного множества  в единицах $10^{-5}$ составляют
\begin{equation*}
\un{\mbf{I}}\, = \,\max_{1 \, \leq k \, \leq n} \,\un{\mbf{x}}_{k} = -5, 3;
\hspace{23mm} 
\ov{\mbf{I}}\, = \,\min_{1 \, \leq k \, \leq n} \,\ov{\mbf{x}}_{k} = -4, 5. 
\end{equation*}  	
	
	\begin{figure}[h!]
		\centering\small 
		\unitlength=1mm
		\begin{picture}(90,55)
			\put(0,0){\includegraphics[width=80mm]{PgammaPhCoverNoTickLabels.png}}
			\put(5,55){$\mbf{x}$}	
			\put(13,3){$1$} 
			\put(40,3){$8$} 
			\put(68,3){$15$} 
			\put(75,35){$\ov{I} = -4,5$}
			\put(75,25){$\un{I} = -5,3$} 
			\put(75,3){\mbox{\small Номер измерения}} 
		\end{picture}
		\caption{Пример обработки накрывающей выборки }
		интервальных измерений
		\label{ScatPlotPicCover} 
	\end{figure} 
 \textit{Центральная оценка} \eqref{MidEstim}  в единицах $10^{-5}$ равна 
\begin{equation*}
	x_{\tt c} \; = \;\m\mbf{I}\; = \;\tfrac{1}{2}\,\bigl(\un{\mbf{I}} + \ov{\mbf{I}}\bigr) = -4, 9. 
\end{equation*} 
В дальнейшем сравним полученные оценки с другими способами оценивания по полной ненакрывающей выборке табл.~\ref{TableData}.
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

%\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Оценки интервальных выборок} 
\label{MeasuresSampleSect} 

В п.~\ref{MeasuresSampleSect} будут введены различные оценки интервальных выборок, рассмотрены конкретные примеры и взаимные отношения различных мер.

\subsection{Мода интервальной выборки} 
\label{ModeSampleSect} 


В традиционной статистике важной характеристикой выборки является ее \emph{мода} 
--- значение из выборки, которое встречается наиболее часто. Для непрерывного 
вероятностного распределения мода --- точка с наибольшей плотностью вероятности. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


\begin{table}[!hp]
	\label{ModeAlgo} 
	\begin{center}
	{Алгоритм нахождения моды\\ 
	интервальной выборки} 
	\end{center}
	\vspace{2pt} 
%	\color{blue} 
	\fboxsep=3mm
	\fboxrule=0.5pt
%	\fbox{\color{black} 
		\begin{minipage}{100mm}
			\centering 
			\begin{tabbing}
				A\= AAA\= AAA\= AAAA\= \hspace{4em}\= \kill
				\>\>\>\>\> \hspace{10pt}\textsf{Вход}                                     \\[2mm] 
				\> Интервальная выборка $\mbf{X} = \{\mbf{x}_{i}\}_{i \, = \, 1}^n$ длины $n$.    \\[5mm] 
				\>\>\>\>\> \hspace{7pt}\textsf{Выход}                                     \\[2mm]
				\> Мода $\mode\mbf{X}$  выборки $\mbf{X}$ и ее частота $\mu$.             \\[5mm] 
				\>\>\>\>\> \textsf{Алгоритм}                                              \\[2mm] 
				\> $\mbf{I}\, \gets \,\bigcap_{i \, = \, 1}^n \mbf{x}_{i}$\,;                     \\[2mm]  
				\> \texttt{IF} \ $\mbf{I}\neq\varnothing$ \  \texttt{THEN}                \\[1mm]  
				\>\> $\mode\mbf{X} \gets \mbf{I}\,$;                                      \\[1mm]  
				\>\> $\mu \gets n$                                                        \\[1mm]  
				\> \texttt{ELSE}                                                          \\[1mm]  
				\>\> объединяем все концы $\un{\mbf{x}}_{1}$, $\ov{\mbf{x}}_{1}$, 
				$\un{\mbf{x}}_{2}$, $\ov{\mbf{x}}_{2}$, \ \ldots, \ 
				$\un{\mbf{x}}_{n}$, $\ov{\mbf{x}}_{n}$                               \\[2pt] 
				\>\> \quad интервалов рассматриваемой выборки $\mbf{X}$ в один            \\[2pt]  
				\>\> \quad массив $\,Y = \{\,y_{1}, y_{2}, \ \ldots, \ y_{N}\}$,  
				где $N\leq 2n$;   \\[1mm] 
				\>\> упорядочиваем элементы $Y$ по возрастанию значений;                  \\[1mm]
				\>\> порождаем интервалы $\mbf{z}_{i} = [y_{i}, y_{i \, + \, 1}]$, 
				$i = 1,2,\ldots,N-1$; \quad   \\[1mm] 
				\>\> для каждого $\mbf{z}_{i}$ подсчитываем число $\mu_i$ интервалов      \\[2pt] 
				\>\>\quad из выборки $\mbf{X}$, включающих интервал $\mbf{z}_{i}\,$;      \\[2mm] 
				\>\> вычисляем $\displaystyle\;\mu\gets \max_{1  \leq \, i \, \leq N-1}\mu_{i}\,$; \\[1mm]   
				\>\> выбираем номера $k$ интервалов $\mbf{z}_k$, для которых $\mu_k$      \\[2pt] 
				\>\> \quad равно максимальному, т.\,е. $\,\mu_{k} = \mu$, и формируем     \\[2pt]
				\>\> \quad из таких $k$ 
				множество $K = \{k\}\subseteq\{ 1,2, \ \ldots, \ N-1\}\,$;     \\[2mm] 
				\>\> $\mode\mbf{X}\, \gets \;\bigcup_{k \, \in K} \mbf{z}_{k}$                \\[3mm] 
				\> \texttt{END IF}.
			\end{tabbing} 
	\end{minipage}
	%} 
\end{table} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
Имеет смысл  распространить понятие моды на обработку интервальных данных, где оно 
будет обозначать интервал тех значений, которые встречаются 
в интервалах обрабатываемых данных наиболее часто. Фактически это означает, что 
точки из моды интервальной выборки накрываются наибольшим числом интервалов этой 
выборки. 
Ясно, что по самому своему определению понятие моды имеет содержательный 
смысл лишь для накрывающих выборок. 
Следуя  \cite{HuCHuZH}, введем следующее определение
\begin{definition} 
	\textsl{Модой} интервальной выборки назовем интервал пересечения ее наибольшей 
	совместной подвыборки.  \index{мода выборки} 
\end{definition} 
Псевдокод алгоритма для нахождения моды выборки интервальных измерений приведен 
в табл.~\ref{ModeAlgo}.   
\begin{example}{Пример вычисления моды интервальной выборки.}
Рассмотрим пример вычисления моды интервальной выборки.
Пусть имеется интервальная выборка из четырех элементов
	\begin{equation}
	\label{ModeExampleData} 
	\mbf{X}   = \{ \ 
	[1, 4],  [5, 9],  [1,5, 4,5],   [6, 9] \  \}.
	\end{equation}	
Диаграмма рассеяния выборки $\mbf{X}$ приведена на рис.~\ref{f:ModelData2hor}.	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
	
	\begin{figure}[htb]
		%	\begin{center}
		\setlength{\unitlength}{1mm} 
		\begin{picture}(100,43)
		\put(15,0){\includegraphics[width=80mm]{ModelData2hor.png}}
		\put(22,38){\mbox{\small Номер измерения}} 
		\put(8,8){\mbox{\small 1}} 
		\put(8,16){\mbox{\small 2}} 
		\put(8,24){\mbox{\small 3}} 
		\put(8,32){\mbox{\small 4}} 
		\put(24,-1){\mbox{\small 1}} 
		\put(51,-1){\mbox{\small 5}} 
		\put(87,-1){\mbox{\small 9}} 
		\put(97,4){$x$}
		\put(26,6){$\mbf{z}_1$} 
		\put(38,6){$\mbf{z}_2$} 
		\put(73,6){$\mbf{z}_6$} 
		\end{picture}
		\caption{Диаграмма рассеяния интервальной выборки \eqref{ModeExampleData} 
			и элементы выборки $\mbf{z}$} 
		\label{f:ModelData2hor} 
		%	\end{center}
	\end{figure}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	В соответствии с алгоритмом \ref{ModeAlgo}, проверим совместность $\mbf{X}$. 
	Пересечение элементов выборки пусто 
	\begin{equation*} 
	\mbf{I}\, = \,\bigcap_{i \, = \, 1}^n \mbf{x}_{i} = \varnothing.
	\end{equation*} 
	Таким образом, необходимо выполнить шаги алгоритма после ключевого слова \texttt{ELSE}.
		Сформируем массив  интервалов $\mbf{z}$ из концов интервалов $\mbf{X}$:
	\begin{equation}\label{ModeExamplecarray}
	\mbf{z}   = \{ \
	[1,0, 1,5], [1,5, 4,0],  [4,0, 4,5],  [4,5, 5,0], [5,0, 6,0],  [6,0, 9,0], [9,0, 9,0] \  \}.
	\end{equation}	
	Мощность $N$ массива $\mbf{z}$ равна $7$. 
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
	
	\begin{figure}[htb]
		%\begin{center}
		\setlength{\unitlength}{1mm} 
		\begin{picture}(100,31)
		\put(10,0){\includegraphics[width=100mm]{MuArray.png}}
		\put(8,30){$\mu_i$} 
		\put(8,12){\mbox{\small 1}} 
		\put(8,22){\mbox{\small 2}} 
		\put(26,-1){\mbox{\small 1.5}} 
		\put(51,-1){\mbox{\small 4}} 
		\put(70,-1){\mbox{\small 6}} 
		\put(97,-1){\mbox{\small 9}} 
		\put(38,6){$\mbf{z}_2$} 
		\put(83,6){$\mbf{z}_6$} 
		\put(110,4){$x$}
		\end{picture}	
		\caption{Значения частот $\mu_i$, интервальная мода $\mode\mbf{X}$ выборки \eqref{ModeExampleData} и элементы выборки $\mbf{z_k} : k \in K$}
		\label{f:MuArray2} 
		%\end{center}
	\end{figure} 
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
	
	Для каждого интервала $\mbf{z}_{i}$ подсчитываем число $\mu_i$ интервалов из выборки 
	$\mbf{X}$, включающих $\mbf{z}_{i}$, получаем массив $\mu_i$ в виде 
	\begin{equation}
	\label{muarray} 
	\{ 1,   2,   1,   0,   1,   2, 2 \}. 
	\end{equation} 
Mаксимальные $\mu_i$, равные $2$, достигаются для индексного множества 
	\begin{equation*} 
	K = \{ 2, 6, 7 \},
	\end{equation*} 
поэтому частота моды равна $\mu =2$. Как итог, мода является мультиинтервалом (см. п.~\ref{MultiIntervalSect} )
	\begin{equation}
	\label{ModeIni} 
	\mode\mbf{X}\, = \; \bigcup_{k \in K} \mbf{z}_{k}\, = [1,5, 4,0] \cup [6,0, 9,0]. 
	\end{equation} 
	
	На Рис.~\ref{f:MuArray2} значения частот $\mu_i$ \eqref{muarray}  показаны синим цветом, 
	а интервальная мода $\mode\mbf{X}$ \eqref{ModeIni} --- красным цветом. 
\end{example}

{\bf Выборки унимодальные и мультимодальные.} \label{UniMultiModSect} Тот факт, что выборка не является унимодальной, может служить признаком сложной 
внутренней структуры описываемого ею явления. 
Исследуемая величина может, к примеру, не быть 
постоянной, а является композицией нескольких близких постоянных величин. 
Примером может быть природное распределение изотопов ртути  (п.~\ref{NatureIntervals}, рис.~\ref{f:HistHg}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!htb]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(55,45) 
%	\put(0,2){\includegraphics[width=55mm]{MultiMod.eps}}
	\put(0,2){\includegraphics[height=45mm, width=60mm]{MassSpectrumFission.png}}
	\end{picture}
	\caption{Бимодальное распределение масс осколков в делении ядра урана \cite{MassSpectrumNuclearFission}} 
	\label{BiModePic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

Так как выборка, очевидно, является своей подвыборкой, то понятие моды 
совпадает с пересечением всех интервалов выборки в случае ее совместности. 
Если же выборка несовместна, то мода может быть мультиинтервалом. Это 
аналогично ситуации с обычными неинтервальными данными, где мод у выборки или 
у распределения может быть несколько.  


При обработке неинтервальных (точечных) данных распределения вида, показанного 
на рис.~\ref{BiModePic}, обоснованно считаются уже не унимодальными, так как имеют 
более одного явно выраженного пика, хотя и разной высоты. В таком случае требуется дополнительная обработка не только основной моды, но и более слабых.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


	\subsection{Медиана  интервальной выборки} 
\label{MedSampleSect} 

В изложении следуем материалу \cite{MedianaProlubnikov}. 
Для вариационного ряда $\{x_i\}_{i=1}^n, x_i \in \mathbb{R}$ существует несколько определений медианы.
Приведем две из них:

\emph{Медиана} это такое значение (члена вариационного ряда), для которого 
\begin{itemize}
	\item [M1] половина членов ряда (с учетом их частот) лежит слева, а~половина~-~справа от него \label{text:me1} 
	\item [M2] минимальна сумма расстояний от него до других членов ряда с учетом их частот. \label{text:me2} 
\end{itemize}

В качестве интервальной медианы для выборки $\{\boldsymbol{x}_i\}_{i=1}^n, \boldsymbol{x}_i \in \mathbb{IR}$ в  \cite{MedianaProlubnikov} предлагается использовать следующие определения как аналог определениям M1 и M2:

%\begin{enumerate}
%	\item \label{text:ime1} 
	Интервальная медиана --- это интервал $\boldsymbol{r}_m$ со средней (геометрически) накопленной частотой, т.е. сумма накопленных частот слева равна сумме накопленных частот справа:
	\begin{equation} \label{eq:SumLefteqSumRight}
	\sum_{i\,=\,1}^{m-1}f_i = \sum_{i\,= \,m+ \,1}^n f_i,
	\end{equation}
	где $f_i$ --- частота интервала $\boldsymbol{r}_i$ --- количество интервалов из заданного вариационного ряда, в которых содержится $\boldsymbol{r}_i$.
	Если оказалось так, что
	\begin{equation*} 
	\sum_{i=1}^{m}f_i = \sum_{i=m+1}^n f_i,
	\end{equation*}
	то интервальная медиана вычисляется по формуле
	\begin{equation} \label{eq:SumLefteqSumRight2}
	\md (\mbf{X}) = \frac{\boldsymbol{r}_m + \boldsymbol{r}_{m \, + \, 1}}{2}.
	\end{equation}
%	\item \label{text:ime2} 

Интервальная медиана --- это интервал $\boldsymbol{r}_m$ такой, что выполнено:
	\begin{equation} \label{eq:medHausdorff}
	\sum_{i\,=\,1,i \, \neq \, m}^{n}\rho(\boldsymbol{r}_m, \boldsymbol{x}_i) = \underset{\{\boldsymbol{r}_j\}}{\min}\sum_{i \,=1,i\, \neq \,j}^{n}\rho(\boldsymbol{r}_j, \boldsymbol{x}_i),
	\end{equation}
	где $\rho$ хаусдорфово расстояние $\rho(\boldsymbol{a}, \boldsymbol{b})$ между интервалами $\boldsymbol{a}, \boldsymbol{b} \in \mathbb{IR}$.
%\end{enumerate}

При этом интервальная медиана, вычисленная по формулам \eqref{eq:SumLefteqSumRight}, \eqref{eq:SumLefteqSumRight2}, может отличаться от интервальной медианы, вычисленной по формуле \eqref{eq:medHausdorff}.

Конструктивное построение интервальной медианы интервального вариационного ряда во многом сходно с построением интервальной моды, рассмотренной в п.~\ref{ModeSampleSect}.
В табл.~\ref{MedAlgo} приведен алгоритм для нахождения медианы интервальной выборки.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{table}[!hp]
	\centering
	\caption{Алгоритм для нахождения медианы\\ 
		интервальной выборки} 
	\label{MedAlgo} 
	\vspace{2pt} 
%	\color{blue} 
	\fboxsep=3mm
	\fboxrule=0.5pt
%	\fbox{\color{black} 
		\begin{minipage}{100mm}
			\centering 
			\begin{tabbing}
				A\= AAA\= AAA\= AAAA\= \hspace{4em}\= \kill
				\>\>\>\>\> \hspace{10pt}\textsf{Вход}                                     \\[2mm] 
				\> Интервальная выборка $\mbf{X} = \{\mbf{x}_{i}\}_{i\,=\,1}^n$ длины $n$.    \\[5mm] 
				\>\>\>\>\> \hspace{7pt}\textsf{Выход}                                     \\[2mm]
				\> Медиана $\md (\mbf{X})$  выборки $\mbf{X}$.             \\[5mm] 
				\>\>\>\>\> \textsf{Алгоритм}                                              \\[2mm] 
				%>\> $\mu \gets n$                                                        \\[1mm]  
				%\> \texttt{ELSE}                                                          \\[1mm]  
				\>\> объединяем все концы $\un{\mbf{x}}_{1}$, $\ov{\mbf{x}}_{1}$, 
				$\un{\mbf{x}}_{2}$, $\ov{\mbf{x}}_{2}$, \ \ldots, \
				$\un{\mbf{x}}_{n}$, $\ov{\mbf{x}}_{n}$                               \\[2pt] 
				\>\> \quad интервалов рассматриваемой выборки $\mbf{X}$ в один            \\[2pt]  
				\>\> \quad массив $\,Y = \{\,y_{1}, y_{2},  \ldots, \ y_{N}\}$,  
				где $N\leq 2n$;   \\[1mm] 
				\>\> упорядочиваем элементы $Y$ по возрастанию значений;                  \\[1mm]
				\>\> порождаем интервалы $\mbf{z}_{i} = [y_{i}, y_{i \, + \, 1}]$, 
				$i = 1,2,\ldots,N-1$; \quad   \\[1mm] 
				\>\> для каждого $\mbf{z}_{i}$ подсчитываем число $\mu_i$ интервалов      \\[2pt] 
				\>\>\quad из выборки $\mbf{X}$, включающих интервал $\mbf{z}_{i}\,$;      \\[2mm] 
				\>\> для каждого $\mbf{z}_{i} $ подсчитываем сумму частот слева и справа ;                  \\[1mm]
				\>\> выбираем интервал $\mbf{z}_{k}$, для которого выполнено условие \eqref{eq:SumLefteqSumRight} \\[1mm]
				\>\> или \\[1mm]
				\>\> для каждого $\mbf{z}_{i} $ подсчитываем  \\[1mm]
				\>\> сумму расстояний до элементов выборки ;                 \\[1mm]
				\>\> выбираем интервал $\mbf{z}_{k}$, для которого выполнено условие \eqref{eq:medHausdorff} ;\\[3mm]
				\> $\md (\mbf{X})\, \gets \;  \mbf{z}_{k}$.                \\[3mm] 
				%\> \texttt{END IF} 
			\end{tabbing} 
	\end{minipage}
	%} 
\end{table} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
Стоит отметить, что в разбиение $\boldsymbol{r}_i$ интервалов из ряда $\{\boldsymbol{x}_i\}_{i\,=\,1}^n$ могут войти интервалы, которых нет в исходных данных. В таком случае интервальной медианой может оказаться интервал, не входящий в исходную выборку. 
Если в качестве медианы нужен интервал, который будет пересекаться с какими-либо интервалами из исходных данных, то можно провести регуляризацию данных. Тогда в качестве интервальной медианы можно будет взять интервальную медиану, построенную для регуляризованных данных.

\begin{example}{Пример медианы интервальной выборки.}
	Пусть имеется интервальная выборка
	\begin{equation} \label{Prolubnikov4}
	\mbf{X} = \{  \ [5, 10],   [3, 9] \,  [1, 4] \    \}.
	\end{equation}
	Найдем ее медиану двумя способами, следуя алгоритму табл.~\ref{MedAlgo}.
	
Исползуя первый способ, построим массив $\mbf{z}_{i}$ из концов интервалов выборки $\mbf{X}$ \eqref{Prolubnikov4}:
	\begin{equation} \label{subintervals}
	\mbf{z} = \{ \  [1, 3],   [3, 4], [4, 5],   [5, 9],   [9, 10] \ \}
	\end{equation}
	и на его основе --- массив частот 
	\begin{equation*}
	\{  \mu  \} = \{   1, 2, 1, 2, 1  \}.
	\end{equation*}
	
	Согласно \eqref{eq:SumLefteqSumRight} имеем
	\begin{equation*}
	m=3, \quad \md (\mbf{X}) = \mbf{z}_3 = [4, 5].
	\end{equation*}
	
	По второму способу, по формуле \eqref{eq:medHausdorff} ищем $\mbf{z}_{i}$, наименее удаленный от интервалов исходной выборки. Массив расстояний 
	\begin{equation*}
	\{  d  \} = \{   14,  13,   12,    8,   18  \}.
	\end{equation*}
	
	Согласно \eqref{eq:medHausdorff} имеем
	\begin{equation*}
	m=4; \quad \md (\mbf{X}) = \mbf{z}_4 = [5, 9].
	\end{equation*}
	
	В данном примере медианы, вычисленные на основе частот и с учетом хаусдорфовых расстояний, оказались различны.
\end{example}

\subsection{Мера совместности интервальной выборки} 
\label{JaccardSampleSect} 


Для описания выборок, помимо оценок их размеров, желательно иметь дополнительную информацию о мере сходства элементов выборки. В п.~\ref{InteWidClass} был рассмотрен вопрос о классификации выборок в зависимости от соотношения ширин интервалов в выборке по отношению к их полной вариабельности.
При определении накрывающих выборок в п.~\ref{CoverMeasrSect} отмечалось, что понятие невозможно определить строго, поскольку жесткие требования к <<накрытию>> приводят к исключению из рассмотрения подавляющего большинства практических ситуаций.

В различных областях анализа данных в науках о Земле, биологии, информатике используют множество мер сходства множеств \cite{Jaccard}.  
Мера сходства бинарная: $S(A, B) \rightarrow [0, 1] $ --- это вещественная функция между объектами $A, B$. \index{IoU --- Intersection over Union}
Формально  принадлежность к мерам сходства определяется системой аксиом:
\begin{itemize}
	\item ограниченность $0 \leq 	S(A, B)  \leq 1 $;
	\item симметрия $	S(A, B) = S(B,A)  \leq 1$;
	\item рефлексивность $	S(A, B)=1  \Longleftrightarrow A=B $;
	\item транзитивность $ 	A \subseteq B \subseteq C \Longrightarrow   S(A, B) \geq S(A, C)  $.
\end{itemize}
Эти свойства также называют $t$-нормой. Существуют и иные системы аксиом сходства.
\index{$t$-норма}
В компьютерных приложениях (обработка изображений, машинное обучение) меру сходства множеств  обозначают как \emph{IoU} (\emph{Intersection over Union}). В математике часто используют наименование \emph{индекс Жаккара}, по имени математика, предложившего подобную меру. \index{индекс Жаккара} \index{мера сходства}

\label{JaccardMeasure}
По мере развития интервального анализа были введены различные определения и конструкции оценки меры совместности интервальных объектов.
Вместе с тем в практике обработки данных часто необходимо оперировать относительными величинами. В частности, это нужно в связи с необходимостью сопоставления допусков и размеров деталей, погрешности измерителей и значений измеряемых величин и т.п. \cite{Kabir2017}.
 
Введем базовую конструкцию совместности для двух интервалов.
Для иллюстрации идеи рассмотрим  следующую числовую характеристику степени совместности  двух интервалов $\mbf{x}, \mbf{y}$:
\begin{equation}\label{Rwid}
\mathrm{JK}(\mbf{x}, \mbf{y}) = 
\frac{\w (\mbf{x} \wedge \mbf{y} )}{\w (\mbf{x} \vee \mbf{y})}.
\end{equation}
В выражении \eqref{Rwid} используется ширина интервала (см. п.~\ref{InrevalProp}), а вместо операций пересечения и объединения множеств --- операции взятия  минимума ($\wedge$) \eqref{InteMinExpr} и максимума ($\vee$) \eqref{InteMaxExpr} по включению двух величин в полной интервальной арифметике Каухера. В наименовании $\mathrm{JK}(\mbf{x}, \mbf{y})$ буква $\mathrm{J}$ указывает на фамилию 
Jaccard, а $\mathrm{K}$ --- на арифметику Каухера.
В общем случае минимум по включению в выражении \eqref{Rwid} может быть неправильным интервалом. 

Рассмотренная мера обобщает обычное понятие меры совместности на различные типы взаимной совместности интервалов. 
В случае $\mbf{x} \cap \mbf{y} = \varnothing$, $\mbf{x} \wedge \mbf{y}$ --- неправильный интервал, числитель \eqref{Rwid} имеет отрицательное значение. 
В предельном случае вещественных значений $x \neq y$ имеем
\begin{equation*}
\mathrm{JK}(x, y) =-1.
\end{equation*}
В целом получаем
\begin{equation}\label{Rwidrange}
-1 \leq \mathrm{JK}(\mbf{x}, \mbf{y}) \leq 1.
\end{equation}
Таким образом, величина $\mathrm{JK}$  непрерывно описывает ситуации от полной несовместности вещественных значений $x \neq y$ до полного перекрытия интервалов $\mbf{x} = \mbf{y}$.

Мера совместности, введенная  для двух интервалов  в форме \eqref{Rwid}, допускает естественное обобщение в случае интервальной выборки. 
Пусть имеется интервальная выборка  $\mbf{X} = \{ \mbf{x}_i \}, \ i=1,2, \ \ldots, \ n.$
Определим меру $\mathrm{JK}(\mbf{X}) $ как 
\begin{align} 
\mathrm{JK}(\mbf{X}) = 
\frac{\w (\bigwedge_i \mbf{x}_i )}{\w (\bigvee_i \mbf{x}_i)}. \label{RwidSetKR}
\end{align}
Важно, что выражение \eqref{RwidSetKR} переходит в случае интервальной выборки из двух элементов в выражение \eqref{Rwid}. %Таким образом, принцип соотвествия выполнен.

\begin{example}{Пример вычисления меры совместности для накрывающей выборки.}
Пусть имеется интервальная выборка из четырех элементов \eqref{ModeExampleData}, рассмотренная при вычислении интервальной моды в п.~\ref{ModeSampleSect}
\begin{equation*}
\mbf{X}   = \{ 
[1, 4],  [5, 9],  [1,5, 4,5],   [6, 9]   \}.
\end{equation*}	
Диаграмма рассеяния выборки $\mbf{X}$ приведена на рис. \ref{f:ModelData2hor}.
Выберем из нее накрывающую подвыборку
\begin{equation*}
\mbf{X}_{\tt c}   = \{  
[5, 9],   [6, 9]  \}.
\end{equation*}	
Для выборки $\mbf{X}_{\tt c}$  имеем согласно \eqref{RwidSetKR}
	\begin{equation*}
	\mathrm{JK}(\mbf{X}_{\tt c}) = \frac{9-6}{9-5} = 0, 75.
	\end{equation*}
Значение $\mathrm{JK}(\mbf{X}_{\tt c})$ демонстрирует высокую меру сходства элементов выборки $\mbf{X}$.	
\end{example}



	\section{Обработка ненакрывающих выборок} 
\label{NonCoverSampleSect} 

Если выборка --- ненакрывающая, т. е. некоторые из ее измерений не содержат истинного 
значения измеряемой величины, то приведенные в п.~\ref{CoverSampleProcSect}  рассуждения и приемы 
частично теряют свой смысл. 
Уточнение пересечением здесь уже неуместно, и информационное множество для истинного 
значения величины имеет смысл взять в виде объединения всех интервалов выборки, 
т.\,е. как 
\begin{equation} 
\label{UnionInterval} 
\bigcup_{1\, \leq k\leq \, n} \mbf{x}_{k}. 
\end{equation} 

Это множество может не быть единым интервалом на вещественной оси (подобное часто 
случается, к примеру, если выборка несовместна). Следует воспользоваться 
вместо объединения обобщающей его операцией <<$\vee$>> (см.~\eqref{InteMaxExpr}), 
т.\,е. взятием максимума по включению, и вместо \eqref{UnionInterval} использовать 
информационный интервал в виде 
\begin{equation} 
\label{UNInterval} 
\mbf{J}\; = \;\bigvee_{1\ \, leq k\leq \, n} \mbf{x}_{k} \ 
= \  \Bigl[\,\min_{1 \, \leq k\leq \, n} \un{\mbf{x}}_{k}, 
\max_{1 \, \leq k\leq \, n} \ov{\mbf{x}}_{k}\,\Bigr]. 
\end{equation} 
Точечной оценкой измеряемой величины может быть середина полученного интервала, т.\,е. 
\begin{equation} \label{midUNInterval} 
x_\text{c} \  = \  \m\mbf{J} \   
= \  \tfrac{1}{2} \Bigl(\min_{1 \, \leq k\leq \, n} \un{\mbf{x}}_{k} + 
\max_{1 \, \leq k\leq \, n} \ov{\mbf{x}}_{k} \Bigr). 
\end{equation} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h!]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(90,60)
	\put(0,0){\includegraphics[width=90mm]{ExampleNonCover.png}}
	\put(75,9){\mbox{\small Номер измерения}} 
	\put(28,45){\mbox{\small $\mbf{x}_1$}}
	\put(50,25){\mbox{\small $\mbf{x}_k$}}
	\put(79,43){\mbox{\small $\mbf{x}_N$}}
	%		\put(2,35){\mbox{\small $\r \mbf{I} \left\lbrace  \right. $}}	
	\put(17,59){\mbox{\small $ \mbf{J}$}}
	\put(37,19){\mbox{\small \ldots }}
	\put(65,19){\mbox{\small \ldots}}
	\put(10,34){\vector(0,1){23}}	
	\put(10,57){\vector(0,-1){23}}
	\put(0,45){\mbox{\small $\r \mbf{J}  $}}			
	\put(0,33){\mbox{\small $\m \mbf{J}$}}	
	\put(7,60){\mbox{\small $ \mbf{x}$}}
	\put(7,22){\mbox{\small $\check{x}$}}		
	\put(25,3){\mbox{\small 1}}
	\put(37,3){\mbox{\small \ldots }}
	\put(65,3){\mbox{\small \ldots}}
	\put(48,3){\mbox{\small $k$}}
	\put(77,3){\mbox{\small $N$}}
	\end{picture}
	\caption{Обработка ненакрывающей выборки интервальных измерений величины. }
	\label{NEnclConstPic} 
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Как и ранее, нам может быть известен некоторый априорный интервал возможных значений 
оцениваемой постоянной величины $\mbf{J}_\text{апр} = [\un{\mbf{J}}_\text{апр}, 
\ov{\mbf{J}}_\text{апр}]$, который должен гарантированно содержать ее. Его могут 
задавать внешние физические (химические, биологические, экономические и т.\,п.) условия 
или ограничения. Тогда границы результирующего интервала \eqref{UNInterval} могут быть 
уточнены пересечением 
\begin{equation}
\label{ImpUNInterval}
\mbf{J} = \mbf{J} \,\cap \,\mbf{J}_{\text{апр}}. 
\end{equation}                                     
%В данной ситуации это уточнение имеет даже б\'{о}льший смысл, чем в случае накрывающей выборки. 

\begin{example}{Неопределенность измерения нуля  цифрового измерителя напряжения.}
Рассмотрим неопределенность измерения нуля цифрового измерителя напряжения. Это явление может быть 
причиной возникновения интервальной неопределенности результатов измерений и упоминается 
в п.~\ref{MeasuResultSect}. 

Пусть в качестве измерителя используется микросхема аналоговой пямяти DRS4 для записи 
коротких сигналов \cite{DRS4}. Перед проведением основных измерений необходимо вычислить неопределенность измерения нуля. Для этого на вход измерителя подают нулевое значение напряжения и получают выборку замеров. 

При дальнейшей обработке данных полученной таким образом выборки возможны различные варианты, соотносящиеся с шириной интервалов по отношению к разбросу средних значений в выборке, как это рассматривалось в п.~\ref{InteWidClass}. 
Дело в том, что измерение выборки электрического сигнала может производиться с различной 
точностью, причем точность измерения может варьироваться в весьма широких пределах. 

В цифровых измерителях напряжения для грубых измерений типичными являются измерители с восемью двоичными разрядами, что соответствует амплитудному разрешению, равному $1/2^8 
\cdot \, 100 \, \% \simeq 0,4 \, \% $. Для более точных измерений разрядность измерителя зависит 
от частоты проводимых измерений и варьируется от 10 ($\simeq 0,1 \,  \%$) до 24 ($\simeq 10^{-5}\,  \%$) 
двоичных разрядов.

В п.~\ref{MeasuResultSect} введено понятие  модели погрешности измерений. В конкретном случае можно в качестве модели измерения \eqref{GeneralErrorModel} принять выражение
\begin{equation} 
	\mbf{x} = \mathring{x} + \mbf{\epsilon}, 
\end{equation}
$\mathring{x}$ --- значение, выданное измерителем, а интервал погрешности принять в виде уравновешенного интервала  
\begin{equation}\label{ErrorNOB}
	\mbf{\epsilon} = [-\epsilon, \epsilon] \quad \epsilon = \frac{1}{2^{\mathit{N \!O\!B}}},
\end{equation}
где $\mathit{N \!O\!B}$ (number of bits) --- разрядность измерителя.
При этом предполагается, что систематические погрешности отсутствуют или неизвестны. 

\begin{figure}[htb]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(100,58)
		\put(-10,53){\mbox{\small Данные}} 
		\put(-10,50){\mbox{\small измерений, В}}	
		\put(90,55){\mbox{\small $ \max_{1 \, \leq \, k \, \leq \, n} \ov{\mbf{x}}_{k}$}} 
		\put(90,32){\mbox{\small $x_\text{c}  $}}	
		\put(10,0){\includegraphics[width=0.7\textwidth]{ExampleNonCoverDataLines.png}}
		\put(90,12){\mbox{\small $ \min_{1 \, \leq \, k \, \leq \, n} \un{\mbf{x}}_{k}$}} 
		\put(87,5){\mbox{\small Номер}} 
		\put(87,2){\mbox{\small измерения}} 
	\end{picture}
	\caption{Диаграмма рассеяния интервальных   измерений}
	неопределенности нуля. %цифрового измерителя напряжения
	Разрядность измерителя $\mathit{N \!O\!B} = 14$
	\label{DRS4ZeroLine100cell1} 
\end{figure}  

Пусть паспортная разрядность цифрового измерителя равна 14 двоичным разрядам.
На рис.~\ref{DRS4ZeroLine100cell1} представлены данные для 100 измерений неопределенности нуля  $\left\lbrace \mathring{x}_k\right\rbrace _{k \,= \,1}^{100}$. 
По характеру данных, представленных на рис.~\ref{DRS4ZeroLine100cell1} видно, что для конкретной 
точности измерителя, ширины интервалов отдельных измерений по модели \eqref{ErrorNOB} малы 
в сравнении с полным диапазоном значений в выборке. 

В п.~\ref{InteWidClass}, говорится о том, что в такой ситуации следует обратить внимание 
на  характер пересечений пар результатов отдельных замеров $ \mbf{x}_i \cap \mbf{x}_j $. 
Из рис.~\ref{DRS4ZeroLine100cell1} видно, что число непустых пересечений относительно 
невелико. 
В этом случае можно применять подходы и алгоритмы, которые используются для неинтервальных 
(точечных) данных. 	Информативно построение гистограммы множества $\left\lbrace 
\mathring{x}_k \right\rbrace _{k \,= \,1}^{100} $. 

Гистограмма для выборки  $\left\lbrace \mathring{x}_k\right\rbrace _{k\,=\,1}^{100}$ представлена 
на рис.~\ref{HISTZeroLine} и демонстрирует несимметричное распределение величины неопределенности нуля и непохожа на популярные теоретико-вероятностные распределения. В такой ситуации для того, чтобы не привносить в обработку данных необоснованных модельных представлений, имеет смысл ограничиться наиболее общими оценками, рассмотренными в начале п.~\ref{NonCoverSampleSect}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[htb]
\centering\small 
\unitlength=1mm
\begin{picture}(100,58)
	\put(10,0){\includegraphics[width=0.7\textwidth]{HISTZeroLineResolution=14.png}}
	\put(-6,53){\mbox{\small Число}} 
	\put(-6,50){\mbox{\small измерений}}
	\put(-6,47){\mbox{\small в столбце}}
	\put(-6,44){\mbox{\small гистограммы}}
	%		\put(10,0){\includegraphics[width=0.7\textwidth]{HISTZeroLineCh=1cell=1resolution=12Example371.png}}
	\put(86,5){\mbox{\small Диапазон}} 
	\put(86,2){\mbox{\small измерений, В}} 
\end{picture}
\caption{Гистограмма данных $\left\lbrace \mathring{x}_k\right\rbrace _{k\,=\,1}^{100}$ 
	интервальных   измерений } неопределенности нуля. Разрядность измерителя $\mathit{N \!O\!B} = 14$
\label{HISTZeroLine} 
\end{figure}  
%  неопределенность измерения нуля цифрового измерителя напряжения
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Согласно выражению \eqref{UNInterval}, имеем оценку информационного множества неопределенности нуля
\begin{equation*} 
%\label{UNInterval} 
\mbf{J}\; = \;\bigvee_{1\leq \, k \, \leq \, n} \mbf{x}_{k} \ 
= \  \Bigl[\,\min_{1 \, \leq \, k \, \leq \, n} \un{\mbf{x}}_{k}, 
\max_{1 \, \leq \, k\leq \, n} \ov{\mbf{x}}_{k}\,\Bigr] = \left[ 0,\!73 \cdot 10^{-3}, \, 6,\!90 \cdot 10^{-3} \right].
\end{equation*} 
Точечная оценка неопределенности нуля \eqref{midUNInterval} равна
\begin{equation*}
x_\text{c} \  = \  \m\mbf{J} \   
= \  \tfrac{1}{2} \Bigl(\,\min_{1 \, \leq \, k\ \, \leq \, n} \un{\mbf{x}}_{k} + 
\max_{1 \, \leq \, k \, \leq \, n} \ov{\mbf{x}}_{k}\,\Bigr) = 3,\!82 \cdot 10^{-3}. 
\end{equation*} 

В целом вид диаграммы рассеяния на рис.~\ref{DRS4ZeroLine100cell1} и гистограммы распределения значений $\left\lbrace \mathring{x}_k\right\rbrace _{k \,=\,1}^{100}$, на рис.~\ref{HISTZeroLine} свидетельствует о переоценке точности представления результатов измерения или недоучете систематических погрешностей. Иначе говоря, модель ошибки \eqref{ErrorNOB}, включающая только погрешность квантования цифрового измерителя, не описывает корректно данные, и суммарная ошибка в каждом измерении  больше. В таком случае можно применить к выборке процедуру варьирования неопределенности, описанную  в п.~\ref{UncertAlterSect}, и добиться совместности данных (получить накрывающую выборку).
\end{example}
Другой возможный сценарий обработки данных ненакрывающей выборки может состоять в том, 
что вместо пересечения интервальных измерений (как в п.~\ref{CoverSampleProcSect}) 
используем обобщающую ее операцию <<$\wedge$>>, т.\,е. взятие минимума всех 
интервальных результатов измерений относительно упорядочения по включению, которое 
задается как % Определением~\ref{PrimaryConceptChap}: %.\arabic{IncluDefi}: 
\begin{equation}
\label{IncluMin} 
\mbf{I} \  = \   
\bigwedge_{1 \leq \,k\,\leq \,n} \mbf{x}_{k} \   = \  
\Bigl[\,\max_{1 \leq \, k \, \leq \, n} \un{\mbf{x}}_{k}, 
\min_{1  \leq \, k \, \leq \, n} \ov{\mbf{x}}_{k}\,\Bigr].  
\end{equation} 
В данном случае требуется использование полной интервальной арифметики Каухера, 
так как интервал \eqref{IncluMin} может оказаться неправильным. Следовательно, 
в качестве точечной оценки измеряемой величины целесообразно взять 
\begin{equation}
\label{WidOptEst} 
x_\text{c} \  = \  \m\mbf{I} \  
= \  \tfrac{1}{2}\Bigl(\,\max_{1\leq \, k \,\leq \,n} \un{\mbf{x}}_{k} 
+ \min_{1\leq \, k\,\leq \, n} \ov{\mbf{x}}_{k}\,\Bigr), 
\end{equation} 
т.\,е. середину интервала, который получается как минимум по включению всех интервалов 
выборки (см. \eqref{InteMinExpr}). Если выборка совместна, то \eqref{WidOptEst} совпадает 
с \eqref{MidEstim}. Если же выборка несовместна, то результатом \eqref{IncluMin} является 
неправильный интервал $\mbf{I}$, $\r\mbf{I} < 0$. Следовательно, информационное множество 
результатов измерений по обрабатываемой выборке пусто. 

Но даже когда интервал \eqref{IncluMin} неправилен, его середина \eqref{WidOptEst} 
--- это точка, обладающая определенными условиями оптимальности. Она первой появляется 
в непустом пересечении интервалов выборки, если  равномерно уширять их, 
увеличивая неопределенность измерений (см. п.~\ref{UncertAlterSect}). 
Если увеличить радиусы всех интервалов выборки на $s$ и
взять $s$ таким, чтобы $s\geq|\r\mbf{I}|$, то получившийся интервал станет правильным, 
и точка $x_\text{c}$ будет лежать в нем. Можно также сказать, что в точке \eqref{WidOptEst} 
минимизируется равномерное уширение интервалов данных рассматриваемой выборки, 
необходимое для достижения ее совместности. 

Наконец, если выборка интервальных измерений --- ненакрывающая, то иногда имеет смысл 
взять среднее арифметическое образующих ее интервалов, т.\,е. 
\begin{equation*} 
\mbf{K} = \frac{1}{n}\;\sum_{k=1}^n \mbf{x}_k . 
\end{equation*} 
Середина $\mbf{K}$ может служить точечной оценкой измеряемой величины. 

Все три рассмотренных приема обработки ненакрывающей 
выборки при стремлении ширины интервальных данных к нулю переходят в методы  
оценивания постоянной величины по точечным данным. 
То есть эти методы удовлетворяют принципу соответствия, рассмотренному в ~п.\ref{InteStatistiSect}. 

\begin{example}{Пример вычисления меры совместности для ненакрывающей выборки}
	Пусть имеется интервальная выборка из четырех элементов \eqref{ModeExampleData} 
	\begin{equation*}
	\mbf{X}   = \{  
	[1, 4],  [5, 9],  [1,5, 4,5],   [6, 9] \}.
	\end{equation*}	
	Диаграмма рассеяния выборки $\mbf{X}$ приведена на рис. \ref{f:ModelData2hor}.
	Для выборки $\mbf{X}$ \eqref{ModeExampleData} имеем согласно \eqref{RwidSetKR}
	\begin{equation*}
	\mathrm{JK}(\mbf{X}) = \frac{4-6}{9-1} = -0,\!25.
	\end{equation*}
Отрицательность $\mathrm{JK}$ говорит о несовместности  выборки $\mbf{X}$, а абсолютная величина --- о степени несовместности ее элементов.
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\section{Вариабельность оценки и варьирование неопределенности.} 
\label{ConstVariabSect}

Рассмотрим  характеристики разброса оценок постоянной величины, полученных 
для интервальной выборки. Ее наиболее естественной мерой, если информационный интервал 
непуст, является \textit{радиус} $\varrho$, т.\,е. 
\begin{equation*}
\varrho\; = \;\r\mbf{I}\; = \;\tfrac{1}{2}\,\bigl(\ov{\mbf{I}} - \un{\mbf{I}}\bigr). 
\end{equation*} 
Фактически это максимальное отклонение границ информационного интервала от центральной 
оценки. 

При анализе данных необходимо знать отклонения точечных или интервальных измерений 
выборки от итоговой точечной оценки. Они дают возможность судить о степени разброса 
измерений относительно полученной оценки, что помогает при анализе качества выборки 
и выявлении выбросов. \textit{Отклонения} $\Delta_k$ для первичных интервальных измерений  
рассчитываются как 
\begin{equation}
\label{MeasurDiffs} 
\Delta_k = \dist(\mbf{x}_{k}, x_{\text{c}}),  \qquad  k = 1, \ \ldots, \ n. 
\end{equation}  

В некоторых случаях имеет смысл отсчитывать отклонения от базовых точечных измерений, 
вокруг которых строятся далее интервальные результаты, т.\,е. рассматривать в качестве 
отклонений результатов отдельных измерений величины 
\begin{equation}
\label{MeasurDiffsAbs} 
\Delta_k = | \mathring{x}_k  - x_{\text{c}} |,  \qquad  k = 1, \ \ldots, \ n.  
\end{equation}  

Норма вектора $\Delta = (\Delta_{1}, \ \ldots, \ \Delta_{n})$ может служить аналогом выборочной 
дисперсии оценки из традиционной вероятностной статистики.  


\begin{example}{Пример вычисления вариабельности оценки.} 
Рассмотрим данные табл.~\ref{TableData} из п.~\ref{CoverSampleProcSect}. 
Точечная оценка равна
\begin{equation} \label{xc}
	x_c = \m \mbf{X} = -5,\!15.
\end{equation}

Информационный интервал множества пуст, поэтому непосредственно вычислить вариабельность невозможно.
Однако можно произвести вычисление максимального отклонения границ информационного интервала от центральной  оценки. 

Возьмем максимум по включению элементов множества интервальных данных из табл.~\ref{TableData}
\begin{equation*}
\mbf{X}_U = \bigvee_i \mbf{x}_i =[ -14,\!4, 4,\!1  ],
\end{equation*}
и вычислим радиус $\mbf{X}_U$:
\begin{equation*}
\varrho\; = \tfrac{1}{2}\,\bigl(\ov{\mbf{X}}_U - \un{\mbf{X}}_U\bigr) = 9,\!25. 
\end{equation*} 
В данном случае это максимальное отклонение границ интервала максимума по включению от центральной оценки. 

Вычисления по формуле \eqref{MeasurDiffsAbs} дают вектор 
\begin{align*}
%\label{DeltaxcPhPgamma}
\Delta_k = \{ 3,\!45,   3,\!65, 4,\!14, 6,\!35, 6,\!85, 9,\!14, 7,\!84, 3,\!14, \\
9,\!34,  9,\!15, 5,\!35, 3,\!54, 2,\!35, 3,\!24, 3,\!85 \} .
\end{align*}  
Приведем пример вычисления различных норм  вектора рассеяния $\Delta_k $
\begin{align*}
| \Delta | : = \begin{cases}
\quad | \Delta |_1 =  81,\!45,\\
\quad| \Delta |_2 = 22,\!98, \\
\quad | \Delta |_{\infty} = 9,\!35. \\
\end{cases}
\end{align*}
\end{example} 
\label{VariabilitySect}

Ранее показано, что величина реальной неопределенности измерения, т.\,е. радиуса 
интервала измерения, определяется непросто и иногда неоднозначно. Однако, он сильно влияет на свойства как отдельного измерения, так и выборки интервальных измерений. 

Изложенное ранее приводит к мысли о том, что при обработке интервальных данных величиной 
неопределенности можно управлять, варьируя ее с целью исследования 
интервальных измерений, их выборок и построения оценок с нужными свойствами. В этом 
состоит суть приема варьирования неопределенности \index{прием варьирования неопределенности} \label{UncertAlterSect} \cite{OskorbinMaksiZhilin}.

Если выборка интервальных измерений несовместна, то, увеличивая одновременно величину 
неопределенности всех измерений, можно добиться того, чтобы выборка стала
совместной, т.\,е. чтобы пересечение интервалов стало непустым, а интервал  
минимума по включению \eqref{IncluMin} --- правильным. Кроме того, точка (или точки), которая первой 
появляется в непустом пересечении интервалов при расширении интервальных 
измерений и тем самым требует наименьшего увеличения неопределенности измерений 
для достижения  совместности выборки, является наименее несовместной. Ее разумно 
исользовать в качестве оценки величины (или оценки параметров зависимости). 

В конкретной ситуации данных табл.~\ref{TableData}, измерения выборки являются существенно неравноширинными. Одновременное изменение величины неопределенности для всех измерений на одно и то же значение может оказаться неразумным. Пусть задан некоторый положительный весовой вектор $w = (w_{1}, w_{2}, \ \ldots, \ w_{n})$,  $w_{k} > 0$, размерность которого равна длине исследуемой выборки, причем изменение величины неопределенности $k$-го измерения  $\r\mbf{x}_k$ должно быть пропорциональным $w_k$, т.\,е. для любых $k$ и $l$ справедливо 
\begin{equation*} 
\frac{\text{Изменение} \ \r\mbf{x}_k}{\text{Изменение} \ \r\mbf{x}_l} = \frac{w_k}{w_l}. 
\end{equation*} 

\begin{example}{Пример варьирования неопределенности.}
Применительно к данным табл. \ref{TableData}, использование методики приведено на рис.~\ref{OskorbinCenter}. Красным цветом представлены исходные данные табл. \ref{TableData}, а черным цветом --- расширенные интервалы данных при выбранном коэффициенте расширения.

\begin{figure}[htb]
	\centering\small 
	\unitlength=1mm
	\begin{picture}(90,60)
	\put(5,0){\includegraphics[width=80mm]{PgammaPhOskorbin.png}}
	\put(-5,53){\mbox{\small Номер}} 
	\put(-5,50){\mbox{\small измерения}} 
	\put(45,0){\mbox{\small Данные}} 
	\end{picture}
	\caption{Графическое представление интервальных данных и результаты обработки по методике \cite{OskorbinMaksiZhilin}} 
	\label{OskorbinCenter} 
\end{figure} 


Вычисления проведены с использованием кода {\tt Octave} С.\,И.\,Жилина  \cite{IntervalAnalysisExamples}. \index{Octave}
При этом решается задача линейного программирования, в ходе которой вычисляются два параметра: оптимальное положение центра неопределенности и коэффициент расширения радиусов замеров. 
$$ x_{MM}={\tt oskorbin\_center} = - 5,\!30; \quad  {\tt k} = 1,\!75. $$
В даном случаев индексе $x_{MM}$ обозначение MM соответствует Minimal Module --- функции оптимизации задачи линейного программирования. 

Информационное множество представляет точку
\begin{equation*} 
\mbf{I}_{MM}	= \bigcap_{1\leq \, k\leq \, n} \mbf{x}_{k} \;\ = \; x_{MM}. 
\end{equation*} 
Содержательным результатом вычислений является уточнение положения наиболее вероятной точечной оценки физической величины \cite{Pgamma1992} и вычисление дополнительной погрешности для каждого элемента выборки, необходимой для достижения совместности данных.
\end{example}
